{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "File",
            "id": "File-3hhla",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-TSdGU",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-File-3hhla{œdataTypeœ:œFileœ,œidœ:œFile-3hhlaœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-SplitText-TSdGU{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-TSdGUœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "File-3hhla",
        "sourceHandle": "{œdataTypeœ:œFileœ,œidœ:œFile-3hhlaœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SplitText-TSdGU",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-TSdGUœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-dnG5s",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LanguageModelComponent-Wh9ZU",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-dnG5s{œdataTypeœ:œPromptœ,œidœ:œPrompt-dnG5sœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-LanguageModelComponent-Wh9ZU{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-Wh9ZUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-dnG5s",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-dnG5sœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LanguageModelComponent-Wh9ZU",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-Wh9ZUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-Wh9ZU",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-5TNCH",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-LanguageModelComponent-Wh9ZU{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-Wh9ZUœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-5TNCH{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-5TNCHœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "LanguageModelComponent-Wh9ZU",
        "sourceHandle": "{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-Wh9ZUœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-5TNCH",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-5TNCHœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-TSdGU",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "CustomComponent-AoAOF",
            "inputTypes": [
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__SplitText-TSdGU{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-TSdGUœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-CustomComponent-AoAOF{œfieldNameœ:œingest_dataœ,œidœ:œCustomComponent-AoAOFœ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitText-TSdGU",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-TSdGUœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "CustomComponent-AoAOF",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œCustomComponent-AoAOFœ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-toSlI",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding_model",
            "id": "CustomComponent-AoAOF",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIEmbeddings-toSlI{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-toSlIœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-CustomComponent-AoAOF{œfieldNameœ:œembedding_modelœ,œidœ:œCustomComponent-AoAOFœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIEmbeddings-toSlI",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-toSlIœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "CustomComponent-AoAOF",
        "targetHandle": "{œfieldNameœ:œembedding_modelœ,œidœ:œCustomComponent-AoAOFœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-FIzBs",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "NeonDatabase-IlpF8",
            "inputTypes": [
              "Message"
            ],
            "type": "query"
          }
        },
        "id": "xy-edge__ChatInput-FIzBs{œdataTypeœ:œChatInputœ,œidœ:œChatInput-FIzBsœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-NeonDatabase-IlpF8{œfieldNameœ:œsearch_queryœ,œidœ:œNeonDatabase-IlpF8œ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}",
        "selected": false,
        "source": "ChatInput-FIzBs",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-FIzBsœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "NeonDatabase-IlpF8",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œNeonDatabase-IlpF8œ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-GRWc8",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding_model",
            "id": "NeonDatabase-IlpF8",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIEmbeddings-GRWc8{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-GRWc8œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-NeonDatabase-IlpF8{œfieldNameœ:œembedding_modelœ,œidœ:œNeonDatabase-IlpF8œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIEmbeddings-GRWc8",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-GRWc8œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "NeonDatabase-IlpF8",
        "targetHandle": "{œfieldNameœ:œembedding_modelœ,œidœ:œNeonDatabase-IlpF8œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "NeonDatabase",
            "id": "NeonDatabase-IlpF8",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "parser-gFolS",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__NeonDatabase-IlpF8{œdataTypeœ:œNeonDatabaseœ,œidœ:œNeonDatabase-IlpF8œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-parser-gFolS{œfieldNameœ:œinput_dataœ,œidœ:œparser-gFolSœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "NeonDatabase-IlpF8",
        "sourceHandle": "{œdataTypeœ:œNeonDatabaseœ,œidœ:œNeonDatabase-IlpF8œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "parser-gFolS",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œparser-gFolSœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "parser",
            "id": "parser-gFolS",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-eJzz1",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__parser-gFolS{œdataTypeœ:œparserœ,œidœ:œparser-gFolSœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-TextOutput-eJzz1{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-eJzz1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "parser-gFolS",
        "sourceHandle": "{œdataTypeœ:œparserœ,œidœ:œparser-gFolSœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-eJzz1",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-eJzz1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-FIzBs",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "What is a good puzzle game to play with my family of 4?"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "selected_output": "message",
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatInput-FIzBs",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 827.4877596995269,
          "y": 421.8759496538444
        },
        "positionAbsolute": {
          "x": 743.9745420290319,
          "y": 463.6977510207854
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-dnG5s",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "context",
                "question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "context": {
                "advanced": false,
                "display_name": "context",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "context",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "question": {
                "advanced": false,
                "display_name": "question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "{context}\n\n---\n\nGiven the context above, answer the question about getting board game recommendations in list format.\n\nQuestion: {question}\n\nAnswer: "
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "prompt",
          "type": "Prompt"
        },
        "dragging": false,
        "height": 433,
        "id": "Prompt-dnG5s",
        "measured": {
          "height": 433,
          "width": 320
        },
        "position": {
          "x": 1997.8297472214626,
          "y": 633.0956607876984
        },
        "positionAbsolute": {
          "x": 1977.9097981422992,
          "y": 640.5656416923846
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Split text into chunks based on specified criteria.",
          "display_name": "Split Text",
          "id": "SplitText-TSdGU",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "frozen": false,
            "icon": "scissors-line-dashed",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks",
                "group_outputs": false,
                "method": "split_text",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_overlap": {
                "advanced": false,
                "display_name": "Chunk Overlap",
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "list": false,
                "name": "chunk_overlap",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 200
              },
              "chunk_size": {
                "advanced": false,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "The maximum length of each chunk. Text is first split by separator, then chunks are merged up to this size. Individual splits larger than this won't be further divided.",
                "list": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#split-text\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Input\",\n            info=\"The data with texts to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=(\n                \"The maximum length of each chunk. Text is first split by separator, \"\n                \"then chunks are merged up to this size. \"\n                \"Individual splits larger than this won't be further divided.\"\n            ),\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=(\n                \"The character to split on. Use \\\\n for newline. \"\n                \"Examples: \\\\n\\\\n for paragraphs, \\\\n for lines, . for sentences\"\n            ),\n            value=\"\\n\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keep_separator\",\n            display_name=\"Keep Separator\",\n            info=\"Whether to keep the separator in the output chunks and where to place it.\",\n            options=[\"False\", \"True\", \"Start\", \"End\"],\n            value=\"False\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"dataframe\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def _fix_separator(self, separator: str) -> str:\n        \"\"\"Fix common separator issues and convert to proper format.\"\"\"\n        if separator == \"/n\":\n            return \"\\n\"\n        if separator == \"/t\":\n            return \"\\t\"\n        return separator\n\n    def split_text_base(self):\n        separator = self._fix_separator(self.separator)\n        separator = unescape_string(separator)\n\n        if isinstance(self.data_inputs, DataFrame):\n            if not len(self.data_inputs):\n                msg = \"DataFrame is empty\"\n                raise TypeError(msg)\n\n            self.data_inputs.text_key = self.text_key\n            try:\n                documents = self.data_inputs.to_lc_documents()\n            except Exception as e:\n                msg = f\"Error converting DataFrame to documents: {e}\"\n                raise TypeError(msg) from e\n        elif isinstance(self.data_inputs, Message):\n            self.data_inputs = [self.data_inputs.to_data()]\n            return self.split_text_base()\n        else:\n            if not self.data_inputs:\n                msg = \"No data inputs provided\"\n                raise TypeError(msg)\n\n            documents = []\n            if isinstance(self.data_inputs, Data):\n                self.data_inputs.text_key = self.text_key\n                documents = [self.data_inputs.to_lc_document()]\n            else:\n                try:\n                    documents = [input_.to_lc_document() for input_ in self.data_inputs if isinstance(input_, Data)]\n                    if not documents:\n                        msg = f\"No valid Data inputs found in {type(self.data_inputs)}\"\n                        raise TypeError(msg)\n                except AttributeError as e:\n                    msg = f\"Invalid input type in collection: {e}\"\n                    raise TypeError(msg) from e\n        try:\n            # Convert string 'False'/'True' to boolean\n            keep_sep = self.keep_separator\n            if isinstance(keep_sep, str):\n                if keep_sep.lower() == \"false\":\n                    keep_sep = False\n                elif keep_sep.lower() == \"true\":\n                    keep_sep = True\n                # 'start' and 'end' are kept as strings\n\n            splitter = CharacterTextSplitter(\n                chunk_overlap=self.chunk_overlap,\n                chunk_size=self.chunk_size,\n                separator=separator,\n                keep_separator=keep_sep,\n            )\n            return splitter.split_documents(documents)\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n    def split_text(self) -> DataFrame:\n        return DataFrame(self._docs_to_data(self.split_text_base()))\n"
              },
              "data_inputs": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The data with texts to split in chunks.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "name": "data_inputs",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keep_separator": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Keep Separator",
                "dynamic": false,
                "info": "Whether to keep the separator in the output chunks and where to place it.",
                "name": "keep_separator",
                "options": [
                  "False",
                  "True",
                  "Start",
                  "End"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "False"
              },
              "separator": {
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "The character to split on. Use \\n for newline. Examples: \\n\\n for paragraphs, \\n for lines, . for sentences",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\\n"
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "The key to use for the text column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text"
              }
            }
          },
          "selected_output": "chunks",
          "type": "SplitText"
        },
        "dragging": false,
        "height": 475,
        "id": "SplitText-TSdGU",
        "measured": {
          "height": 475,
          "width": 320
        },
        "position": {
          "x": 1692.461995335383,
          "y": 1328.2681481569232
        },
        "positionAbsolute": {
          "x": 1683.4543896546102,
          "y": 1350.7871623588553
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-l7Jwp",
          "node": {
            "description": "## 🐕 2. Retriever Flow\n\nThis flow answers your questions with contextual data retrieved from your vector database.\n\nOpen the **Playground** and ask, \n\n```\nWhat is this document about?\n```\n",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-l7Jwp",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 374.388314931542,
          "y": 486.18094072679895
        },
        "positionAbsolute": {
          "x": 374.388314931542,
          "y": 486.18094072679895
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 324
        },
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "note-iTBkQ",
          "node": {
            "description": "## 📖 README\n\nLoad your data into a vector database with the 📚 **Load Data** flow, and then use your data as chat context with the 🐕 **Retriever** flow.\n\n**🚨 Add your OpenAI API key as a global variable to easily add it to all of the OpenAI components in this flow.** \n\n**Quick start**\n1. Run the 📚 **Load Data** flow.\n2. Run the 🐕 **Retriever** flow.\n\n**Next steps** \n\n- Experiment by changing the prompt and the loaded data to see how the bot's responses change. \n\nFor more info, see the [Langflow docs](https://docs.langflow.org/starter-projects-vector-store-rag).",
            "display_name": "Read Me",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 556,
        "id": "note-iTBkQ",
        "measured": {
          "height": 556,
          "width": 389
        },
        "position": {
          "x": 191.12162720143235,
          "y": 1157.6038620251531
        },
        "positionAbsolute": {
          "x": 94.28986613312418,
          "y": 907.6428043837066
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 324
        },
        "type": "noteNode",
        "width": 389
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-5TNCH",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([safe_convert(item, clean_data=self.clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatOutput-5TNCH",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 2738.611008351098,
          "y": 829.6219994149209
        },
        "positionAbsolute": {
          "x": 2734.385670401691,
          "y": 810.6079786425926
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "OpenAIEmbeddings-GRWc8",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using OpenAI models.",
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embedding Model",
                "group_outputs": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "client": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Client",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "client",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n"
              },
              "default_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Headers",
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "list": false,
                "name": "default_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "default_query": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Query",
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "list": false,
                "name": "default_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "deployment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "embedding_ctx_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Embedding Context Length",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "embedding_ctx_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-small"
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "openai_api_base": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "openai_api_type": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Type",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_type",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_version": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Version",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_version",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_organization": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Organization",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_organization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_proxy": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Proxy",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_proxy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "request_timeout": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Request Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "request_timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "show_progress_bar": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Show Progress Bar",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "show_progress_bar",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "skip_empty": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Skip Empty",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "skip_empty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tiktoken_enable": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "TikToken Enable",
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "list": false,
                "name": "tiktoken_enable",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "tiktoken_model_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "TikToken Model Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tiktoken_model_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "embeddings",
          "type": "OpenAIEmbeddings"
        },
        "dragging": false,
        "height": 320,
        "id": "OpenAIEmbeddings-GRWc8",
        "measured": {
          "height": 320,
          "width": 320
        },
        "position": {
          "x": 825.435626932521,
          "y": 739.6327999745448
        },
        "positionAbsolute": {
          "x": 825.435626932521,
          "y": 739.6327999745448
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-8FBui",
          "node": {
            "description": "## 📚 1. Load Data Flow\n\nRun this first! Load data from a local file and embed it into the vector database.\n\nSelect a Database and a Collection, or create new ones. \n\nClick  **Run component** on the **Astra DB** component to load your data.\n\n\n### Next steps:\n Experiment by changing the prompt and the contextual data to see how the retrieval flow's responses change.",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 460,
        "id": "note-8FBui",
        "measured": {
          "height": 460,
          "width": 340
        },
        "position": {
          "x": 913.9906853654297,
          "y": 1523.8879126168624
        },
        "positionAbsolute": {
          "x": 955.3277857006676,
          "y": 1552.171191793604
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 324
        },
        "type": "noteNode",
        "width": 340
      },
      {
        "data": {
          "id": "OpenAIEmbeddings-toSlI",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using OpenAI models.",
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embedding Model",
                "group_outputs": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "client": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Client",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "client",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n"
              },
              "default_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Headers",
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "list": false,
                "name": "default_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "default_query": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Query",
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "list": false,
                "name": "default_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "deployment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "embedding_ctx_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Embedding Context Length",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "embedding_ctx_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-small"
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "openai_api_base": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "openai_api_type": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Type",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_type",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_version": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Version",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_version",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_organization": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Organization",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_organization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_proxy": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Proxy",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_proxy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "request_timeout": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Request Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "request_timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "show_progress_bar": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Show Progress Bar",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "show_progress_bar",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "skip_empty": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Skip Empty",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "skip_empty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tiktoken_enable": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "TikToken Enable",
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "list": false,
                "name": "tiktoken_enable",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "tiktoken_model_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "TikToken Model Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tiktoken_model_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "embeddings",
          "type": "OpenAIEmbeddings"
        },
        "dragging": false,
        "height": 320,
        "id": "OpenAIEmbeddings-toSlI",
        "measured": {
          "height": 320,
          "width": 320
        },
        "position": {
          "x": 1690.9220896443658,
          "y": 1866.483269483266
        },
        "positionAbsolute": {
          "x": 1690.9220896443658,
          "y": 1866.483269483266
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-ttnzy",
          "node": {
            "description": "### 💡 Add your OpenAI API key here 👇",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "transparent"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-ttnzy",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 1692.2322233423606,
          "y": 1821.9077961087607
        },
        "positionAbsolute": {
          "x": 1692.2322233423606,
          "y": 1821.9077961087607
        },
        "selected": false,
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "note-ledmB",
          "node": {
            "description": "### 💡 Add your OpenAI API key here 👇",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "transparent"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-ledmB",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 824.1003268813427,
          "y": 698.6951695764802
        },
        "positionAbsolute": {
          "x": 824.1003268813427,
          "y": 698.6951695764802
        },
        "selected": false,
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "note-SJNRF",
          "node": {
            "description": "### 💡 Add your OpenAI API key here 👇",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "transparent"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-SJNRF",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 2350.297636215281,
          "y": 577.4592910079571
        },
        "positionAbsolute": {
          "x": 2350.297636215281,
          "y": 525.0687902842766
        },
        "selected": false,
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "parser-gFolS",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
            "display_name": "Parser",
            "documentation": "",
            "edited": false,
            "field_order": [
              "mode",
              "pattern",
              "input_data",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "parser",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "hidden": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TabInput,\n)\nfrom langflow.schema import Data, DataFrame\nfrom langflow.schema.message import Message\n\n\nclass ParserComponent(Component):\n    name = \"parser\"\n    display_name = \"Parser\"\n    description = (\n        \"Format a DataFrame or Data object into text using a template. \"\n        \"Enable 'Stringify' to convert input into a readable string instead.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                return json.dumps(data.data)\n            if isinstance(data, DataFrame):\n                if hasattr(self, \"clean_data\") and self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\n        else:\n            result = self._safe_convert(self.input_data)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{name} ({year_published}) ================================================================================  RANKINGS & METRICS:    Search Position: #{rank} | BGG Rank: #{bgg_rank} | ID: {id}    Rating: {rating_average}/10 from {users_rated} users    Complexity: {complexity_average}/5 | Owned by: {owned_users} people  GAME SPECIFICATIONS:    Players: {min_players}-{max_players} | Duration: {play_time} minutes    Age: {min_age}+ | Year: {year_published}  CATEGORIZATION:    Domains: {domains}    Mechanics: {mechanics}  RESOURCES:    BoardGameGeek: {url}  DESCRIPTION:    {description}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "selected_output": "parsed_text",
          "showNode": true,
          "type": "parser"
        },
        "dragging": false,
        "id": "parser-gFolS",
        "measured": {
          "height": 358,
          "width": 320
        },
        "position": {
          "x": 1583.5982144641368,
          "y": 651.635660385082
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "File-3hhla",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Loads content from one or more files as a DataFrame.",
            "display_name": "File",
            "documentation": "",
            "edited": false,
            "field_order": [
              "path",
              "file_path",
              "separator",
              "silent_errors",
              "delete_server_file_after_processing",
              "ignore_unsupported_extensions",
              "ignore_unspecified_files",
              "use_multithreading",
              "concurrency_multithreading"
            ],
            "frozen": false,
            "icon": "file-text",
            "last_updated": "2025-09-26T01:16:35.917Z",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Structured Content",
                "group_outputs": false,
                "hidden": null,
                "method": "load_files_structured",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Raw Content",
                "group_outputs": false,
                "method": "load_files_message",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "File Path",
                "group_outputs": false,
                "hidden": null,
                "method": "load_files_path",
                "name": "path",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from copy import deepcopy\nfrom typing import Any\n\nfrom langflow.base.data.base_file import BaseFileComponent\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data\nfrom langflow.io import BoolInput, FileInput, IntInput, Output\nfrom langflow.schema.data import Data\n\n\nclass FileComponent(BaseFileComponent):\n    \"\"\"Handles loading and processing of individual or zipped text files.\n\n    This component supports processing multiple valid files within a zip archive,\n    resolving paths, validating file types, and optionally using multithreading for processing.\n    \"\"\"\n\n    display_name = \"File\"\n    description = \"Loads content from one or more files.\"\n    documentation: str = \"https://docs.langflow.org/components-data#file\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    VALID_EXTENSIONS = TEXT_FILE_TYPES\n\n    _base_inputs = deepcopy(BaseFileComponent._base_inputs)\n\n    for input_item in _base_inputs:\n        if isinstance(input_item, FileInput) and input_item.name == \"path\":\n            input_item.real_time_refresh = True\n            break\n\n    inputs = [\n        *_base_inputs,\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"[Deprecated] Use Multithreading\",\n            advanced=True,\n            value=True,\n            info=\"Set 'Processing Concurrency' greater than 1 to enable multithreading.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=True,\n            info=\"When multiple files are being processed, the number of files to process concurrently.\",\n            value=1,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the number of files processed.\"\"\"\n        if field_name == \"path\":\n            # Add outputs based on the number of files in the path\n            if len(field_value) == 0:\n                return frontend_node\n\n            frontend_node[\"outputs\"] = []\n\n            if len(field_value) == 1:\n                # We need to check if the file is structured content\n                file_path = frontend_node[\"template\"][\"path\"][\"file_path\"][0]\n                if file_path.endswith((\".csv\", \".xlsx\", \".parquet\")):\n                    frontend_node[\"outputs\"].append(\n                        Output(display_name=\"Structured Content\", name=\"dataframe\", method=\"load_files_structured\"),\n                    )\n                elif file_path.endswith(\".json\"):\n                    frontend_node[\"outputs\"].append(\n                        Output(display_name=\"Structured Content\", name=\"json\", method=\"load_files_json\"),\n                    )\n\n                # All files get the raw content and path outputs\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n                )\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"File Path\", name=\"path\", method=\"load_files_path\"),\n                )\n            else:\n                # For multiple files, we only show the files output\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Files\", name=\"dataframe\", method=\"load_files\"),\n                )\n\n        return frontend_node\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Processes files either sequentially or in parallel, depending on concurrency settings.\n\n        Args:\n            file_list (list[BaseFileComponent.BaseFile]): List of files to process.\n\n        Returns:\n            list[BaseFileComponent.BaseFile]: Updated list of files with merged data.\n        \"\"\"\n\n        def process_file(file_path: str, *, silent_errors: bool = False) -> Data | None:\n            \"\"\"Processes a single file and returns its Data object.\"\"\"\n            try:\n                return parse_text_file_to_data(file_path, silent_errors=silent_errors)\n            except FileNotFoundError as e:\n                msg = f\"File not found: {file_path}. Error: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n            except Exception as e:\n                msg = f\"Unexpected error processing {file_path}: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        concurrency = 1 if not self.use_multithreading else max(1, self.concurrency_multithreading)\n        file_count = len(file_list)\n\n        parallel_processing_threshold = 2\n        if concurrency < parallel_processing_threshold or file_count < parallel_processing_threshold:\n            if file_count > 1:\n                self.log(f\"Processing {file_count} files sequentially.\")\n            processed_data = [process_file(str(file.path), silent_errors=self.silent_errors) for file in file_list]\n        else:\n            self.log(f\"Starting parallel processing of {file_count} files with concurrency: {concurrency}.\")\n            file_paths = [str(file.path) for file in file_list]\n            processed_data = parallel_load_data(\n                file_paths,\n                silent_errors=self.silent_errors,\n                load_function=process_file,\n                max_concurrency=concurrency,\n            )\n\n        # Use rollup_basefile_data to merge processed data with BaseFile objects\n        return self.rollup_data(file_list, processed_data)\n"
              },
              "concurrency_multithreading": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Processing Concurrency",
                "dynamic": false,
                "info": "When multiple files are being processed, the number of files to process concurrently.",
                "list": false,
                "list_add_label": "Add More",
                "name": "concurrency_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "delete_server_file_after_processing": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Delete Server File After Processing",
                "dynamic": false,
                "info": "If true, the Server File Path will be deleted after processing.",
                "list": false,
                "list_add_label": "Add More",
                "name": "delete_server_file_after_processing",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "file_path": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "Server File Path",
                "dynamic": false,
                "info": "Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.",
                "input_types": [
                  "Data",
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "file_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ignore_unspecified_files": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unspecified Files",
                "dynamic": false,
                "info": "If true, Data with no 'file_path' property will be ignored.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ignore_unspecified_files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "ignore_unsupported_extensions": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unsupported Extensions",
                "dynamic": false,
                "info": "If true, files with unsupported extensions will not be processed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ignore_unsupported_extensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "zip",
                  "tar",
                  "tgz",
                  "bz2",
                  "gz"
                ],
                "file_path": [
                  "3199d7f8-a104-49d0-b6bd-2acae425e9dd/bbg_desc_combined_full.csv"
                ],
                "info": "Supported file extensions: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx; optionally bundled in file extensions: zip, tar, tgz, bz2, gz",
                "list": true,
                "list_add_label": "Add More",
                "name": "path",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "temp_file": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "separator": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "Specify the separator to use between multiple outputs in Message format.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n\n"
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "list": false,
                "list_add_label": "Add More",
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "use_multithreading": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "[Deprecated] Use Multithreading",
                "dynamic": false,
                "info": "Set 'Processing Concurrency' greater than 1 to enable multithreading.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "message",
          "showNode": true,
          "type": "File"
        },
        "dragging": false,
        "id": "File-3hhla",
        "measured": {
          "height": 232,
          "width": 320
        },
        "position": {
          "x": 1330.7650978046952,
          "y": 1431.5905495627503
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-Wh9ZU",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider. ",
            "display_name": "Language Model",
            "documentation": "",
            "edited": false,
            "field_order": [
              "provider",
              "model_name",
              "api_key",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "last_updated": "2025-09-26T01:16:35.917Z",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_openai import ChatOpenAI\n\nfrom langflow.base.models.anthropic_constants import ANTHROPIC_MODELS\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\nfrom langflow.schema.dotdict import dotdict\n\n\nclass LanguageModelComponent(LCModelComponent):\n    display_name = \"Language Model\"\n    description = \"Runs a language model given a specified provider.\"\n    documentation: str = \"https://docs.langflow.org/components-models\"\n    icon = \"brain-circuit\"\n    category = \"models\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Model Provider\",\n            options=[\"OpenAI\", \"Anthropic\", \"Google\"],\n            value=\"OpenAI\",\n            info=\"Select the model provider\",\n            real_time_refresh=True,\n            options_metadata=[{\"icon\": \"OpenAI\"}, {\"icon\": \"Anthropic\"}, {\"icon\": \"GoogleGenerativeAI\"}],\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            info=\"Select the model to use\",\n            real_time_refresh=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"Model Provider API key\",\n            required=False,\n            show=True,\n            real_time_refresh=True,\n        ),\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input text to send to the model\",\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"A system message that helps set the behavior of the assistant\",\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=\"Whether to stream the response\",\n            value=False,\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Controls randomness in responses\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        provider = self.provider\n        model_name = self.model_name\n        temperature = self.temperature\n        stream = self.stream\n\n        if provider == \"OpenAI\":\n            if not self.api_key:\n                msg = \"OpenAI API key is required when using OpenAI provider\"\n                raise ValueError(msg)\n\n            if model_name in OPENAI_REASONING_MODEL_NAMES:\n                # reasoning models do not support temperature (yet)\n                temperature = None\n\n            return ChatOpenAI(\n                model_name=model_name,\n                temperature=temperature,\n                streaming=stream,\n                openai_api_key=self.api_key,\n            )\n        if provider == \"Anthropic\":\n            if not self.api_key:\n                msg = \"Anthropic API key is required when using Anthropic provider\"\n                raise ValueError(msg)\n            return ChatAnthropic(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                anthropic_api_key=self.api_key,\n            )\n        if provider == \"Google\":\n            if not self.api_key:\n                msg = \"Google API key is required when using Google provider\"\n                raise ValueError(msg)\n            return ChatGoogleGenerativeAI(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                google_api_key=self.api_key,\n            )\n        msg = f\"Unknown provider: {provider}\"\n        raise ValueError(msg)\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"provider\":\n            if field_value == \"OpenAI\":\n                build_config[\"model_name\"][\"options\"] = OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES\n                build_config[\"model_name\"][\"value\"] = OPENAI_CHAT_MODEL_NAMES[0]\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\n            elif field_value == \"Anthropic\":\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\n            elif field_value == \"Google\":\n                build_config[\"model_name\"][\"options\"] = GOOGLE_GENERATIVE_AI_MODELS\n                build_config[\"model_name\"][\"value\"] = GOOGLE_GENERATIVE_AI_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Google API Key\"\n        elif field_name == \"model_name\" and field_value.startswith(\"o1\") and self.provider == \"OpenAI\":\n            # Hide system_message for o1 models - currently unsupported\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        elif field_name == \"model_name\" and not field_value.startswith(\"o1\") and \"system_message\" in build_config:\n            build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Select the model to use",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "provider": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "Select the model provider",
                "name": "provider",
                "options": [
                  "OpenAI",
                  "Anthropic",
                  "Google"
                ],
                "options_metadata": [
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "OpenAI"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "dragging": false,
        "id": "LanguageModelComponent-Wh9ZU",
        "measured": {
          "height": 447,
          "width": 320
        },
        "position": {
          "x": 2354.7612483129965,
          "y": 633.8261067248878
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-AoAOF",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "VectorStore"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Ingest and search documents in Neon Database with pgvector. Handles pre-chunked data.",
            "display_name": "Neon Database",
            "documentation": "https://neon.tech/docs",
            "edited": true,
            "field_order": [
              "connection_string",
              "collection_name",
              "embedding_model",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "search_method",
              "vector_dimensions",
              "distance_metric",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "advanced_search_filter",
              "autodetect_collection",
              "content_field",
              "metadata_field",
              "deletion_field",
              "ignore_invalid_documents",
              "batch_size",
              "output_template",
              "neon_vectorstore_kwargs"
            ],
            "frozen": false,
            "icon": "PostgreSQL",
            "last_updated": "2025-09-26T01:16:35.918Z",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "group_outputs": false,
                "hidden": null,
                "method": "search_documents",
                "name": "search_results",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "as_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Vector Store Connection",
                "group_outputs": false,
                "hidden": true,
                "method": "as_vector_store",
                "name": "vectorstoreconnection",
                "options": null,
                "required_inputs": null,
                "selected": "VectorStore",
                "tool_mode": true,
                "types": [
                  "VectorStore"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "advanced_search_filter": {
                "_input_type": "NestedDictInput",
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "list": false,
                "list_add_label": "Add More",
                "name": "advanced_search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "NestedDict",
                "value": {}
              },
              "autodetect_collection": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Autodetect Collection",
                "dynamic": false,
                "info": "Boolean flag to determine whether to autodetect the collection.",
                "list": false,
                "list_add_label": "Add More",
                "name": "autodetect_collection",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "batch_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Batch Size",
                "dynamic": false,
                "info": "Number of documents to process in each batch to avoid token limits.",
                "list": false,
                "list_add_label": "Add More",
                "name": "batch_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\r\nimport asyncio\r\nfrom collections import defaultdict\r\nfrom dataclasses import asdict, dataclass, field\r\nfrom typing import Optional, List, Dict, Any\r\n\r\nimport psycopg2\r\nfrom psycopg2.extras import RealDictCursor\r\nfrom sqlalchemy import create_engine, text\r\nfrom pgvector.sqlalchemy import Vector\r\nfrom langchain_postgres import PGVector\r\nfrom langchain_core.documents import Document\r\nfrom langchain_core.embeddings import Embeddings\r\n\r\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom langflow.base.vectorstores.vector_store_connection_decorator import vector_store_connection\r\nfrom langflow.helpers.data import docs_to_data\r\nfrom langflow.inputs.inputs import FloatInput, NestedDictInput\r\nfrom langflow.io import (\r\n    BoolInput,\r\n    DropdownInput,\r\n    HandleInput,\r\n    IntInput,\r\n    QueryInput,\r\n    SecretStrInput,\r\n    StrInput,\r\n)\r\nfrom langflow.schema.data import Data\r\nfrom langflow.serialization import serialize\r\nfrom langflow.utils.version import get_version_info\r\n\r\n\r\n@vector_store_connection\r\nclass NeonDatabaseVectorStoreComponent(LCVectorStoreComponent):\r\n    display_name: str = \"Neon Database\"\r\n    description: str = \"Ingest and search documents in Neon Database with pgvector. Handles pre-chunked data.\"\r\n    documentation: str = \"https://neon.tech/docs\"\r\n    name = \"NeonDatabase\"\r\n    icon: str = \"PostgreSQL\"\r\n\r\n    _cached_vector_store: PGVector | None = None\r\n\r\n    @dataclass\r\n    class NewCollectionInput:\r\n        functionality: str = \"create\"\r\n        fields: dict[str, dict] = field(\r\n            default_factory=lambda: {\r\n                \"data\": {\r\n                    \"node\": {\r\n                        \"name\": \"create_collection\",\r\n                        \"description\": \"Please allow several seconds for creation to complete.\",\r\n                        \"display_name\": \"Create new collection\",\r\n                        \"field_order\": [\r\n                            \"01_new_collection_name\",\r\n                            \"02_dimension\",\r\n                            \"03_distance_metric\",\r\n                        ],\r\n                        \"template\": {\r\n                            \"01_new_collection_name\": StrInput(\r\n                                name=\"new_collection_name\",\r\n                                display_name=\"Collection Name\",\r\n                                info=\"Name of the new collection to create in Neon Database.\",\r\n                                required=True,\r\n                            ),\r\n                            \"02_dimension\": IntInput(\r\n                                name=\"dimension\",\r\n                                display_name=\"Vector Dimensions\",\r\n                                info=\"Dimensions of the vectors to store.\",\r\n                                value=1536,\r\n                                required=True,\r\n                            ),\r\n                            \"03_distance_metric\": DropdownInput(\r\n                                name=\"distance_metric\",\r\n                                display_name=\"Distance Metric\",\r\n                                info=\"Distance metric for vector similarity search.\",\r\n                                options=[\"cosine\", \"euclidean\", \"inner_product\"],\r\n                                value=\"cosine\",\r\n                                required=True,\r\n                            ),\r\n                        },\r\n                    },\r\n                }\r\n            }\r\n        )\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"connection_string\",\r\n            display_name=\"Connection String\",\r\n            info=\"Direct connection string to your Neon Database. Get this from Neon Console → Connection Details. Format: postgresql://user:pass@host:port/db?sslmode=require\",\r\n            required=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"collection_name\",\r\n            display_name=\"Collection\",\r\n            info=\"The name of the collection (table) within Neon Database where the vectors will be stored.\",\r\n            required=True,\r\n            refresh_button=True,\r\n            real_time_refresh=True,\r\n            dialog_inputs=asdict(NewCollectionInput()),\r\n            combobox=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Specify the Embedding Model for vector generation.\",\r\n            required=True,\r\n        ),\r\n        *LCVectorStoreComponent.inputs,\r\n        DropdownInput(\r\n            name=\"search_method\",\r\n            display_name=\"Search Method\",\r\n            info=\"Determine how your content is matched: Vector finds semantic similarity.\",\r\n            options=[\"Vector Search\"],\r\n            options_metadata=[{\"icon\": \"SearchVector\"}],\r\n            value=\"Vector Search\",\r\n            advanced=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        IntInput(\r\n            name=\"vector_dimensions\",\r\n            display_name=\"Vector Dimensions\",\r\n            info=\"Dimensions of the embedding vectors.\",\r\n            advanced=True,\r\n            value=1536,\r\n        ),\r\n        DropdownInput(\r\n            name=\"distance_metric\",\r\n            display_name=\"Distance Metric\",\r\n            info=\"Distance metric for vector similarity search.\",\r\n            options=[\"cosine\", \"euclidean\", \"inner_product\"],\r\n            value=\"cosine\",\r\n            advanced=True,\r\n        ),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Search Results\",\r\n            info=\"Number of search results to return.\",\r\n            advanced=True,\r\n            value=4,\r\n        ),\r\n        DropdownInput(\r\n            name=\"search_type\",\r\n            display_name=\"Search Type\",\r\n            info=\"Search type to use\",\r\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\r\n            value=\"Similarity\",\r\n            advanced=True,\r\n        ),\r\n        FloatInput(\r\n            name=\"search_score_threshold\",\r\n            display_name=\"Search Score Threshold\",\r\n            info=\"Minimum similarity score threshold for search results. \"\r\n            \"(when using 'Similarity with score threshold')\",\r\n            value=0,\r\n            advanced=True,\r\n        ),\r\n        NestedDictInput(\r\n            name=\"advanced_search_filter\",\r\n            display_name=\"Search Metadata Filter\",\r\n            info=\"Optional dictionary of filters to apply to the search query.\",\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"autodetect_collection\",\r\n            display_name=\"Autodetect Collection\",\r\n            info=\"Boolean flag to determine whether to autodetect the collection.\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        StrInput(\r\n            name=\"content_field\",\r\n            display_name=\"Content Field\",\r\n            info=\"Field to use as the text content field for the vector store.\",\r\n            advanced=True,\r\n            value=\"page_content\",\r\n        ),\r\n        StrInput(\r\n            name=\"metadata_field\",\r\n            display_name=\"Metadata Field\",\r\n            info=\"Field to use for storing document metadata.\",\r\n            advanced=True,\r\n            value=\"metadata\",\r\n        ),\r\n        StrInput(\r\n            name=\"deletion_field\",\r\n            display_name=\"Deletion Based On Field\",\r\n            info=\"When this parameter is provided, documents in the target collection with \"\r\n            \"metadata field values matching the input metadata field value will be deleted \"\r\n            \"before new data is loaded.\",\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"ignore_invalid_documents\",\r\n            display_name=\"Ignore Invalid Documents\",\r\n            info=\"Boolean flag to determine whether to ignore invalid documents at runtime.\",\r\n            advanced=True,\r\n        ),\r\n        IntInput(\r\n            name=\"batch_size\",\r\n            display_name=\"Batch Size\",\r\n            info=\"Number of documents to process in each batch to avoid token limits.\",\r\n            advanced=True,\r\n            value=10,\r\n        ),\r\n        StrInput(\r\n            name=\"output_template\",\r\n            display_name=\"Output Template\",\r\n            info=\"Template for formatting BoardGameGeek search results. Available placeholders: {id}, {name}, {game_name}, {description}, {domains}, {mechanics}, {year_published}, {min_players}, {max_players}, {play_time}, {min_age}, {users_rated}, {rating_average}, {bgg_rank}, {complexity_average}, {owned_users}, {url}, {rank}, {score}. Leave empty for JSON output. Use 'DEBUG' to see available fields.\",\r\n            advanced=True,\r\n            value=\"Game: {name}\\nYear: {year_published}\\nRating: {rating_average}/10 (BGG Rank #{bgg_rank})\\nPlayers: {min_players}-{max_players} | Time: {play_time}min | Age: {min_age}+\\nType: {domains}\\nMechanics: {mechanics}\\nComplexity: {complexity_average}/5\\nDescription: {description}\",\r\n        ),\r\n        NestedDictInput(\r\n            name=\"neon_vectorstore_kwargs\",\r\n            display_name=\"Neon VectorStore Parameters\",\r\n            info=\"Optional dictionary of additional parameters for the PGVector store.\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    @classmethod\r\n    def _get_content_field(cls) -> str:\r\n        return \"page_content\"\r\n    \r\n    @classmethod\r\n    def _get_metadata_field(cls) -> str:\r\n        return \"metadata\"\r\n\r\n    def get_database_object(self):\r\n        \"\"\"Get database connection object.\"\"\"\r\n        try:\r\n            if not self.connection_string:\r\n                raise ValueError(\"Connection string is required\")\r\n                \r\n            engine = create_engine(self.connection_string)\r\n            return engine\r\n        except Exception as e:\r\n            msg = f\"Error creating database connection: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n    def collection_data(self, collection_name: str):\r\n        \"\"\"Get collection metadata and document count.\"\"\"\r\n        try:\r\n            engine = self.get_database_object()\r\n            \r\n            with engine.connect() as conn:\r\n                # Check if table exists\r\n                result = conn.execute(text(\"\"\"\r\n                    SELECT EXISTS (\r\n                        SELECT FROM information_schema.tables \r\n                        WHERE table_name = :table_name\r\n                    );\r\n                \"\"\"), {\"table_name\": collection_name})\r\n                \r\n                if not result.scalar():\r\n                    return None\r\n                \r\n                # Get document count\r\n                count_result = conn.execute(text(f\"SELECT COUNT(*) FROM {collection_name}\"))\r\n                return count_result.scalar()\r\n                \r\n        except Exception as e:\r\n            self.log(f\"Error checking collection data: {e}\")\r\n            return None\r\n\r\n    def _initialize_collection_options(self):\r\n        \"\"\"Initialize collection options for dropdown.\"\"\"\r\n        try:\r\n            engine = self.get_database_object()\r\n            collections = []\r\n            \r\n            with engine.connect() as conn:\r\n                # Get all tables that have vector columns\r\n                result = conn.execute(text(\"\"\"\r\n                    SELECT table_name \r\n                    FROM information_schema.columns \r\n                    WHERE column_name = 'embedding' \r\n                    AND table_schema = 'public';\r\n                \"\"\"))\r\n                \r\n                for row in result:\r\n                    table_name = row[0]\r\n                    collections.append({\r\n                        \"name\": table_name,\r\n                        \"records\": self.collection_data(table_name),\r\n                        \"type\": \"vector_table\",\r\n                    })\r\n                    \r\n            return collections\r\n        except Exception as e:\r\n            self.log(f\"Error fetching collection options: {e}\")\r\n            return []\r\n\r\n    def reset_collection_list(self, build_config: dict) -> dict:\r\n        \"\"\"Reset collection list options based on provided configuration.\"\"\"\r\n        try:\r\n            if not self.connection_string:\r\n                collection_config = build_config[\"collection_name\"]\r\n                collection_config.update({\"options\": [], \"options_metadata\": [], \"value\": \"\", \"show\": False})\r\n                return build_config\r\n                \r\n            collection_options = self._initialize_collection_options()\r\n            \r\n            collection_config = build_config[\"collection_name\"]\r\n            collection_config.update(\r\n                {\r\n                    \"options\": [col[\"name\"] for col in collection_options],\r\n                    \"options_metadata\": [{k: v for k, v in col.items() if k != \"name\"} for col in collection_options],\r\n                }\r\n            )\r\n            \r\n            if collection_config[\"value\"] not in collection_config[\"options\"]:\r\n                collection_config[\"value\"] = \"\"\r\n                \r\n            collection_config[\"show\"] = bool(self.connection_string)\r\n            \r\n        except Exception as e:\r\n            self.log(f\"Error resetting collection list: {e}\")\r\n            \r\n        return build_config\r\n\r\n    def reset_build_config(self, build_config: dict) -> dict:\r\n        \"\"\"Reset all build configuration options to default empty state.\"\"\"\r\n        collection_config = build_config[\"collection_name\"]\r\n        collection_config.update({\"options\": [], \"options_metadata\": [], \"value\": \"\", \"show\": False})\r\n        \r\n        # For Neon Database, embedding model is always required\r\n        build_config[\"embedding_model\"][\"show\"] = True\r\n        build_config[\"embedding_model\"][\"required\"] = True\r\n        \r\n        return build_config\r\n\r\n    async def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\r\n        \"\"\"Update build configuration based on field name and value.\"\"\"\r\n        # Collection creation callback\r\n        if field_name == \"collection_name\" and isinstance(field_value, dict):\r\n            if \"01_new_collection_name\" in field_value:\r\n                await self._create_new_collection(build_config, field_value)\r\n                return build_config\r\n                \r\n        # Connection string change\r\n        if field_name == \"connection_string\":\r\n            return self.reset_collection_list(build_config)\r\n            \r\n        # Collection selection change\r\n        if field_name == \"collection_name\" and not isinstance(field_value, dict):\r\n            return self._handle_collection_selection(build_config, field_value)\r\n            \r\n        # Initial execution\r\n        first_run = field_name == \"collection_name\" and not field_value and not build_config[\"collection_name\"][\"options\"]\r\n        if first_run:\r\n            return self.reset_collection_list(build_config)\r\n            \r\n        return build_config\r\n\r\n    async def _create_new_collection(self, build_config: dict, field_value: dict) -> None:\r\n        \"\"\"Create a new collection and update build config options.\"\"\"\r\n        try:\r\n            await self.create_collection_api(\r\n                new_collection_name=field_value[\"01_new_collection_name\"],\r\n                connection_string=self.connection_string,\r\n                dimension=field_value.get(\"02_dimension\", 1536),\r\n                distance_metric=field_value.get(\"03_distance_metric\", \"cosine\"),\r\n            )\r\n        except Exception as e:\r\n            msg = f\"Error creating collection: {e}\"\r\n            raise ValueError(msg) from e\r\n            \r\n        build_config[\"collection_name\"].update(\r\n            {\r\n                \"value\": field_value[\"01_new_collection_name\"],\r\n                \"options\": build_config[\"collection_name\"][\"options\"] + [field_value[\"01_new_collection_name\"]],\r\n            }\r\n        )\r\n        \r\n        build_config[\"collection_name\"][\"options_metadata\"].append(\r\n            {\r\n                \"records\": 0,\r\n                \"type\": \"vector_table\",\r\n            }\r\n        )\r\n        \r\n        # Show embedding model input since we're using \"Bring your own\" approach\r\n        build_config[\"embedding_model\"][\"show\"] = True\r\n        build_config[\"embedding_model\"][\"required\"] = True\r\n\r\n    @classmethod\r\n    async def create_collection_api(\r\n        cls,\r\n        new_collection_name: str,\r\n        connection_string: str,\r\n        dimension: int,\r\n        distance_metric: str = \"cosine\",\r\n    ):\r\n        \"\"\"Create a new collection (table) in Neon Database.\"\"\"\r\n        try:\r\n            # Create engine\r\n            engine = create_engine(connection_string)\r\n            \r\n            # Create the vector table\r\n            with engine.connect() as conn:\r\n                # Enable pgvector extension\r\n                conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))\r\n                \r\n                # Create the collection table\r\n                create_table_sql = f\"\"\"\r\n                CREATE TABLE IF NOT EXISTS {new_collection_name} (\r\n                    id SERIAL PRIMARY KEY,\r\n                    {cls._get_content_field()} TEXT NOT NULL,\r\n                    {cls._get_metadata_field()} JSONB,\r\n                    embedding vector({dimension})\r\n                );\r\n                \"\"\"\r\n                conn.execute(text(create_table_sql))\r\n                \r\n                # Create index based on distance metric\r\n                index_sql = f\"\"\"\r\n                CREATE INDEX IF NOT EXISTS {new_collection_name}_embedding_idx \r\n                ON {new_collection_name} \r\n                USING ivfflat (embedding vector_{distance_metric}_ops) \r\n                WITH (lists = 100);\r\n                \"\"\"\r\n                conn.execute(text(index_sql))\r\n                \r\n                conn.commit()\r\n                \r\n        except Exception as e:\r\n            msg = f\"Error creating collection: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n    def _handle_collection_selection(self, build_config: dict, field_value: str) -> dict:\r\n        \"\"\"Handle collection selection and update embedding options.\"\"\"\r\n        build_config[\"autodetect_collection\"][\"value\"] = True\r\n        build_config = self.reset_collection_list(build_config)\r\n        \r\n        if not field_value:\r\n            return build_config\r\n            \r\n        if field_value and field_value not in build_config[\"collection_name\"][\"options\"]:\r\n            build_config[\"collection_name\"][\"options\"].append(field_value)\r\n            build_config[\"collection_name\"][\"options_metadata\"].append(\r\n                {\r\n                    \"records\": 0,\r\n                    \"type\": \"vector_table\",\r\n                }\r\n            )\r\n            build_config[\"autodetect_collection\"][\"value\"] = False\r\n        \r\n        # For Neon Database, we always need an embedding model since we don't have built-in vectorize\r\n        build_config[\"embedding_model\"][\"show\"] = True\r\n        build_config[\"embedding_model\"][\"required\"] = True\r\n            \r\n        return build_config\r\n\r\n    @check_cached_vector_store\r\n    def build_vector_store(self):\r\n        \"\"\"Build the PGVector store.\"\"\"\r\n        try:\r\n            from langchain_postgres import PGVector\r\n        except ImportError as e:\r\n            msg = (\r\n                \"Could not import langchain_postgres package. \"\r\n                \"Please install it with `pip install langchain-postgres`.\"\r\n            )\r\n            raise ImportError(msg) from e\r\n\r\n        # Get the embedding model and additional params\r\n        embedding_params = {\"embedding\": self.embedding_model} if self.embedding_model else {}\r\n        \r\n        if not embedding_params:\r\n            raise ValueError(\"Embedding model is required for Neon Database vector store\")\r\n\r\n        # Get the additional parameters\r\n        additional_params = self.neon_vectorstore_kwargs or {}\r\n\r\n        # Get Langflow version information\r\n        __version__ = get_version_info()[\"version\"]\r\n\r\n        # Get connection details\r\n        if not self.connection_string:\r\n            raise ValueError(\"Connection string is required for Neon Database\")\r\n\r\n        # Bundle up the auto-detect parameters\r\n        autodetect_params = {\r\n            \"pre_delete_collection\": False,\r\n            \"distance_strategy\": self._get_distance_strategy(),\r\n            \"create_extension\": True,\r\n        }\r\n\r\n        # Attempt to build the Vector Store object\r\n        try:\r\n            vector_store = PGVector(\r\n                connection=self.connection_string,\r\n                embeddings=self.embedding_model,\r\n                collection_name=self.collection_name,\r\n                collection_metadata={\"langflow_version\": __version__},\r\n                **autodetect_params,\r\n                **additional_params,\r\n            )\r\n        except Exception as e:\r\n            msg = f\"Error initializing PGVector: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n        # Add documents to the vector store in batches\r\n        self._add_documents_to_vector_store_batched(vector_store)\r\n\r\n        return vector_store\r\n\r\n    def _get_distance_strategy(self) -> str:\r\n        \"\"\"Map distance metric to PGVector distance strategy.\"\"\"\r\n        distance_mapping = {\r\n            \"cosine\": \"cosine\",\r\n            \"euclidean\": \"euclidean\", \r\n            \"inner_product\": \"inner_product\",\r\n        }\r\n        return distance_mapping.get(self.distance_metric, \"cosine\")\r\n\r\n    def _add_documents_to_vector_store_batched(self, vector_store) -> None:\r\n        \"\"\"Add documents to the vector store in batches to avoid token limits.\"\"\"\r\n        self.ingest_data = self._prepare_ingest_data()\r\n\r\n        if not self.ingest_data:\r\n            self.log(\"No documents to add to the Vector Store.\")\r\n            return\r\n\r\n        documents = []\r\n        for _input in self.ingest_data:\r\n            if isinstance(_input, Data):\r\n                documents.append(_input.to_lc_document())\r\n            else:\r\n                msg = \"Vector Store Inputs must be Data objects.\"\r\n                raise TypeError(msg)\r\n\r\n        # Convert to Document objects with serialized metadata\r\n        documents = [\r\n            Document(page_content=doc.page_content, metadata=serialize(doc.metadata, to_str=True)) \r\n            for doc in documents\r\n        ]\r\n\r\n        if documents and self.deletion_field:\r\n            self.log(f\"Deleting documents where {self.deletion_field}\")\r\n            try:\r\n                # Implement deletion logic if needed\r\n                self.log(f\"Deletion field '{self.deletion_field}' specified but deletion not implemented yet.\")\r\n            except Exception as e:\r\n                msg = f\"Error deleting documents from PGVector based on '{self.deletion_field}': {e}\"\r\n                raise ValueError(msg) from e\r\n\r\n        if documents:\r\n            self.log(f\"Adding {len(documents)} documents to the Vector Store in batches of {self.batch_size}.\")\r\n            \r\n            # Process documents in batches\r\n            total_batches = (len(documents) + self.batch_size - 1) // self.batch_size\r\n            \r\n            for i in range(0, len(documents), self.batch_size):\r\n                batch = documents[i:i + self.batch_size]\r\n                batch_num = (i // self.batch_size) + 1\r\n                \r\n                try:\r\n                    self.log(f\"Processing batch {batch_num}/{total_batches} ({len(batch)} documents)\")\r\n                    vector_store.add_documents(batch)\r\n                    self.log(f\"Successfully added batch {batch_num}\")\r\n                except Exception as e:\r\n                    self.log(f\"Error adding batch {batch_num}: {e}\")\r\n                    # Continue with next batch instead of failing completely\r\n                    continue\r\n                    \r\n            self.log(f\"Completed processing all {len(documents)} documents.\")\r\n        else:\r\n            self.log(\"No documents to add to the Vector Store.\")\r\n\r\n    def _map_search_type(self) -> str:\r\n        \"\"\"Map search type to PGVector search method.\"\"\"\r\n        search_type_mapping = {\r\n            \"Similarity with score threshold\": \"similarity_score_threshold\",\r\n            \"MMR (Max Marginal Relevance)\": \"mmr\",\r\n        }\r\n        return search_type_mapping.get(self.search_type, \"similarity\")\r\n\r\n    def _build_search_args(self):\r\n        \"\"\"Build search arguments for vector store search.\"\"\"\r\n        query = self.search_query if isinstance(self.search_query, str) and self.search_query.strip() else None\r\n\r\n        if not query:\r\n            return {}\r\n\r\n        args = {\r\n            \"query\": query,\r\n            \"search_type\": self._map_search_type(),\r\n            \"k\": self.number_of_results,\r\n        }\r\n\r\n        if self.search_type == \"Similarity with score threshold\":\r\n            args[\"score_threshold\"] = self.search_score_threshold\r\n\r\n        filter_arg = self.advanced_search_filter or {}\r\n        if filter_arg:\r\n            args[\"filter\"] = filter_arg\r\n\r\n        return args\r\n\r\n    def search_documents(self, vector_store=None) -> Data:\r\n        \"\"\"Search documents in the vector store and return formatted results as a single Data object.\"\"\"\r\n        vector_store = vector_store or self.build_vector_store()\r\n\r\n        self.log(f\"Search input: {self.search_query}\")\r\n        self.log(f\"Search type: {self.search_type}\")\r\n        self.log(f\"Number of results: {self.number_of_results}\")\r\n\r\n        try:\r\n            search_args = self._build_search_args()\r\n        except Exception as e:\r\n            msg = f\"Error in PGVector._build_search_args: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n        if not search_args:\r\n            self.log(\"No search input provided. Skipping search.\")\r\n            return Data(text=\"\", display_name=\"No Search Results\")\r\n\r\n        docs = []\r\n        search_method = \"similarity_search\"\r\n\r\n        try:\r\n            self.log(f\"Calling vector_store.{search_method} with args: {search_args}\")\r\n            docs = getattr(vector_store, search_method)(**search_args)\r\n        except Exception as e:\r\n            msg = f\"Error performing {search_method} in PGVector: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n        self.log(f\"Retrieved documents: {len(docs)}\")\r\n\r\n        # Convert documents to a single formatted Data object for parsers\r\n        formatted_data = self._format_search_results_for_parser(docs)\r\n        self.log(f\"Formatted documents for parser: {formatted_data.display_name}\")\r\n        self.status = formatted_data\r\n\r\n        return formatted_data\r\n\r\n    def _format_search_results_for_parser(self, docs) -> Data:\r\n        \"\"\"Format search results for use with Langflow parsers and templates.\"\"\"\r\n        if not docs:\r\n            return Data(text=\"\", display_name=\"No Search Results\")\r\n        \r\n        # Check if we're in debug mode\r\n        if self.output_template and self.output_template.strip().upper() == \"DEBUG\":\r\n            return self._debug_mode_output(docs)\r\n        \r\n        # Create data in the exact format Langflow parser expects\r\n        # Based on the error, the parser expects a list of Data objects with specific structure\r\n        formatted_documents = []\r\n        \r\n        for i, doc in enumerate(docs):\r\n            # Extract game data from metadata and content\r\n            metadata = doc.metadata or {}\r\n            content = doc.page_content\r\n            \r\n            # Parse the CSV content to extract game data\r\n            # The content appears to be CSV format: ID,Name,Year,MinPlayers,MaxPlayers,PlayTime,MinAge,UsersRated,Rating,BGGRank,Complexity,OwnedUsers,Mechanics,Domains,URL,Description\r\n            game_data = self._parse_csv_content(content, metadata, i + 1)\r\n            \r\n            # Create Data object with the structure parser expects\r\n            data_obj = Data(\r\n                value=game_data,\r\n                display_name=f\"Game Result {i + 1}\",\r\n                metadata={\"source\": \"neon_search\", \"rank\": i + 1}\r\n            )\r\n            formatted_documents.append(data_obj)\r\n        \r\n        # If using a template, format the results\r\n        if self.output_template and self.output_template.strip():\r\n            formatted_results = []\r\n            \r\n            for data_obj in formatted_documents:\r\n                game_data = data_obj.value\r\n                \r\n                # Convert lists to strings for template formatting\r\n                mechanics_str = \", \".join(game_data[\"mechanics\"]) if isinstance(game_data[\"mechanics\"], list) else str(game_data[\"mechanics\"])\r\n                domains_str = \", \".join(game_data[\"domains\"]) if isinstance(game_data[\"domains\"], list) else str(game_data[\"domains\"])\r\n                \r\n                try:\r\n                    # Use safe formatting with default values\r\n                    formatted_result = self.output_template.format(\r\n                        id=game_data.get(\"id\", \"Unknown\"),\r\n                        game_name=game_data.get(\"game_name\", \"Unknown\"),\r\n                        name=game_data.get(\"name\", \"Unknown\"),\r\n                        description=game_data.get(\"description\", \"No description available\"),\r\n                        domains=domains_str,\r\n                        mechanics=mechanics_str,\r\n                        year_published=game_data.get(\"year_published\", \"Unknown\"),\r\n                        min_players=game_data.get(\"min_players\", \"Unknown\"),\r\n                        max_players=game_data.get(\"max_players\", \"Unknown\"),\r\n                        play_time=game_data.get(\"play_time\", \"Unknown\"),\r\n                        min_age=game_data.get(\"min_age\", \"Unknown\"),\r\n                        users_rated=game_data.get(\"users_rated\", \"Unknown\"),\r\n                        rating_average=game_data.get(\"rating_average\", \"Unknown\"),\r\n                        bgg_rank=game_data.get(\"bgg_rank\", \"Unknown\"),\r\n                        complexity_average=game_data.get(\"complexity_average\", \"Unknown\"),\r\n                        owned_users=game_data.get(\"owned_users\", \"Unknown\"),\r\n                        url=game_data.get(\"url\", \"Unknown\"),\r\n                        rank=game_data.get(\"rank\", \"Unknown\"),\r\n                        score=game_data.get(\"score\", \"N/A\")\r\n                    )\r\n                    formatted_results.append(formatted_result)\r\n                except KeyError as e:\r\n                    self.log(f\"Template error for game {game_data.get('game_name', 'Unknown')} - missing key {e}\")\r\n                    # Fall back to a simple format\r\n                    simple_result = f\"{game_data.get('rank', '?')}. {game_data.get('name', game_data.get('game_name', 'Unknown Game'))}\"\r\n                    formatted_results.append(simple_result)\r\n            \r\n            # Combine all formatted results into a single text\r\n            combined_text = \"\\n\\n\".join(formatted_results)\r\n            \r\n            return Data(\r\n                text=combined_text,\r\n                display_name=f\"Search Results: {len(formatted_results)} games found\",\r\n                metadata={\"source\": \"neon_search\", \"total_results\": len(formatted_results), \"template_used\": True}\r\n            )\r\n        \r\n        else:\r\n            # Return the formatted documents as a list for the parser\r\n            # The parser expects a list of Data objects\r\n            return Data(\r\n                text=str(formatted_documents),\r\n                display_name=f\"Search Results: {len(formatted_documents)} games found\",\r\n                metadata={\"source\": \"neon_search\", \"total_results\": len(formatted_documents), \"format\": \"list\"}\r\n            )\r\n\r\n    def _debug_mode_output(self, docs) -> Data:\r\n        \"\"\"Debug mode to show what data is actually available.\"\"\"\r\n        debug_info = []\r\n        debug_info.append(\"=== DEBUG MODE: Available Data Fields ===\")\r\n        debug_info.append(f\"Found {len(docs)} documents\")\r\n        debug_info.append(\"\")\r\n        \r\n        for i, doc in enumerate(docs[:3]):  # Show first 3 documents\r\n            debug_info.append(f\"--- Document {i+1} ---\")\r\n            debug_info.append(f\"Page Content (first 200 chars): {doc.page_content[:200]}...\")\r\n            debug_info.append(f\"Metadata keys: {list(doc.metadata.keys()) if doc.metadata else 'No metadata'}\")\r\n            \r\n            if doc.metadata:\r\n                for key, value in doc.metadata.items():\r\n                    if isinstance(value, (list, dict)):\r\n                        debug_info.append(f\"  {key}: {type(value).__name__} with {len(value)} items\")\r\n                    else:\r\n                        debug_info.append(f\"  {key}: {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}\")\r\n            debug_info.append(\"\")\r\n        \r\n        debug_text = \"\\n\".join(debug_info)\r\n        \r\n        return Data(\r\n            text=debug_text,\r\n            display_name=\"Debug: Data Structure Analysis\",\r\n            metadata={\"source\": \"neon_search\", \"debug_mode\": True, \"total_docs\": len(docs)}\r\n        )\r\n\r\n    def _parse_csv_content(self, content, metadata, rank):\r\n        \"\"\"Parse CSV content to extract game data.\"\"\"\r\n        import csv\r\n        import io\r\n        \r\n        try:\r\n            # Split the content by commas, but handle quoted fields properly\r\n            reader = csv.reader(io.StringIO(content))\r\n            row = next(reader)\r\n            \r\n            # Expected CSV format: ID,Name,Year,MinPlayers,MaxPlayers,PlayTime,MinAge,UsersRated,Rating,BGGRank,Complexity,OwnedUsers,Mechanics,Domains,URL,Description\r\n            if len(row) >= 16:\r\n                game_data = {\r\n                    \"rank\": rank,\r\n                    \"content\": content,\r\n                    \"metadata\": metadata,\r\n                    \"score\": None,\r\n                    \"id\": row[0] if row[0] else \"Unknown\",\r\n                    \"name\": row[1] if row[1] else \"Unknown\",\r\n                    \"game_name\": row[1] if row[1] else \"Unknown\",\r\n                    \"year_published\": row[2] if row[2] else \"Unknown\",\r\n                    \"min_players\": row[3] if row[3] else \"Unknown\",\r\n                    \"max_players\": row[4] if row[4] else \"Unknown\",\r\n                    \"play_time\": row[5] if row[5] else \"Unknown\",\r\n                    \"min_age\": row[6] if row[6] else \"Unknown\",\r\n                    \"users_rated\": row[7] if row[7] else \"Unknown\",\r\n                    \"rating_average\": row[8] if row[8] else \"Unknown\",\r\n                    \"bgg_rank\": row[9] if row[9] else \"Unknown\",\r\n                    \"complexity_average\": row[10] if row[10] else \"Unknown\",\r\n                    \"owned_users\": row[11] if row[11] else \"Unknown\",\r\n                    \"mechanics\": row[12].split(\", \") if row[12] else [],\r\n                    \"domains\": row[13].split(\", \") if row[13] else [],\r\n                    \"url\": row[14] if row[14] else \"Unknown\",\r\n                    \"description\": row[15] if row[15] else \"No description available\",\r\n                }\r\n            else:\r\n                # Fallback if CSV format is different\r\n                game_data = {\r\n                    \"rank\": rank,\r\n                    \"content\": content,\r\n                    \"metadata\": metadata,\r\n                    \"score\": None,\r\n                    \"id\": \"Unknown\",\r\n                    \"name\": \"Unknown\",\r\n                    \"game_name\": \"Unknown\",\r\n                    \"year_published\": \"Unknown\",\r\n                    \"min_players\": \"Unknown\",\r\n                    \"max_players\": \"Unknown\",\r\n                    \"play_time\": \"Unknown\",\r\n                    \"min_age\": \"Unknown\",\r\n                    \"users_rated\": \"Unknown\",\r\n                    \"rating_average\": \"Unknown\",\r\n                    \"bgg_rank\": \"Unknown\",\r\n                    \"complexity_average\": \"Unknown\",\r\n                    \"owned_users\": \"Unknown\",\r\n                    \"mechanics\": [],\r\n                    \"domains\": [],\r\n                    \"url\": \"Unknown\",\r\n                    \"description\": content,\r\n                }\r\n                \r\n        except Exception as e:\r\n            self.log(f\"Error parsing CSV content: {e}\")\r\n            # Fallback to basic parsing\r\n            game_data = {\r\n                \"rank\": rank,\r\n                \"content\": content,\r\n                \"metadata\": metadata,\r\n                \"score\": None,\r\n                \"id\": \"Unknown\",\r\n                \"name\": \"Unknown\",\r\n                \"game_name\": \"Unknown\",\r\n                \"year_published\": \"Unknown\",\r\n                \"min_players\": \"Unknown\",\r\n                \"max_players\": \"Unknown\",\r\n                \"play_time\": \"Unknown\",\r\n                \"min_age\": \"Unknown\",\r\n                \"users_rated\": \"Unknown\",\r\n                \"rating_average\": \"Unknown\",\r\n                \"bgg_rank\": \"Unknown\",\r\n                \"complexity_average\": \"Unknown\",\r\n                \"owned_users\": \"Unknown\",\r\n                \"mechanics\": [],\r\n                \"domains\": [],\r\n                \"url\": \"Unknown\",\r\n                \"description\": content,\r\n            }\r\n        \r\n        return game_data\r\n\r\n    def get_retriever_kwargs(self):\r\n        \"\"\"Get retriever kwargs for the vector store.\"\"\"\r\n        search_args = self._build_search_args()\r\n\r\n        return {\r\n            \"search_type\": self._map_search_type(),\r\n            \"search_kwargs\": search_args,\r\n        }\r\n"
              },
              "collection_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {
                  "fields": {
                    "data": {
                      "node": {
                        "description": "Please allow several seconds for creation to complete.",
                        "display_name": "Create new collection",
                        "field_order": [
                          "01_new_collection_name",
                          "02_dimension",
                          "03_distance_metric"
                        ],
                        "name": "create_collection",
                        "template": {
                          "01_new_collection_name": {
                            "_input_type": "StrInput",
                            "advanced": false,
                            "display_name": "Collection Name",
                            "dynamic": false,
                            "info": "Name of the new collection to create in Neon Database.",
                            "list": false,
                            "list_add_label": "Add More",
                            "load_from_db": false,
                            "name": "new_collection_name",
                            "placeholder": "",
                            "required": true,
                            "show": true,
                            "title_case": false,
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "type": "str",
                            "value": ""
                          },
                          "02_dimension": {
                            "_input_type": "IntInput",
                            "advanced": false,
                            "display_name": "Vector Dimensions",
                            "dynamic": false,
                            "info": "Dimensions of the vectors to store.",
                            "list": false,
                            "list_add_label": "Add More",
                            "name": "dimension",
                            "placeholder": "",
                            "required": true,
                            "show": true,
                            "title_case": false,
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "type": "int",
                            "value": 1536
                          },
                          "03_distance_metric": {
                            "_input_type": "DropdownInput",
                            "advanced": false,
                            "combobox": false,
                            "dialog_inputs": {},
                            "display_name": "Distance Metric",
                            "dynamic": false,
                            "info": "Distance metric for vector similarity search.",
                            "name": "distance_metric",
                            "options": [
                              "cosine",
                              "euclidean",
                              "inner_product"
                            ],
                            "options_metadata": [],
                            "placeholder": "",
                            "required": true,
                            "show": true,
                            "title_case": false,
                            "toggle": false,
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "type": "str",
                            "value": "cosine"
                          }
                        }
                      }
                    }
                  },
                  "functionality": "create"
                },
                "display_name": "Collection",
                "dynamic": false,
                "info": "The name of the collection (table) within Neon Database where the vectors will be stored.",
                "load_from_db": false,
                "name": "collection_name",
                "options": [
                  "documents",
                  "langchain_pg_embedding"
                ],
                "options_metadata": [
                  {
                    "records": 0,
                    "type": "vector_table"
                  },
                  {
                    "records": 31945,
                    "type": "vector_table"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "langchain_pg_embedding"
              },
              "connection_string": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Connection String",
                "dynamic": false,
                "info": "Direct connection string to your Neon Database. Get this from Neon Console → Connection Details. Format: postgresql://user:pass@host:port/db?sslmode=require",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "connection_string",
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "postgresql://neondb_owner:npg_fzoFW1Bn9GIr@ep-still-brook-af8h1onp-pooler.c-2.us-west-2.aws.neon.tech/neondb?sslmode=require&channel_binding=require"
              },
              "content_field": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Content Field",
                "dynamic": false,
                "info": "Field to use as the text content field for the vector store.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "content_field",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "page_content"
              },
              "deletion_field": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Deletion Based On Field",
                "dynamic": false,
                "info": "When this parameter is provided, documents in the target collection with metadata field values matching the input metadata field value will be deleted before new data is loaded.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "deletion_field",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "distance_metric": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Distance Metric",
                "dynamic": false,
                "info": "Distance metric for vector similarity search.",
                "name": "distance_metric",
                "options": [
                  "cosine",
                  "euclidean",
                  "inner_product"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              },
              "embedding_model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding Model",
                "dynamic": false,
                "info": "Specify the Embedding Model for vector generation.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding_model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ignore_invalid_documents": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Invalid Documents",
                "dynamic": false,
                "info": "Boolean flag to determine whether to ignore invalid documents at runtime.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ignore_invalid_documents",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "metadata_field": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Field",
                "dynamic": false,
                "info": "Field to use for storing document metadata.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_field",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "metadata"
              },
              "neon_vectorstore_kwargs": {
                "_input_type": "NestedDictInput",
                "advanced": true,
                "display_name": "Neon VectorStore Parameters",
                "dynamic": false,
                "info": "Optional dictionary of additional parameters for the PGVector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "neon_vectorstore_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "NestedDict",
                "value": {}
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Search Results",
                "dynamic": false,
                "info": "Number of search results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "output_template": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Output Template",
                "dynamic": false,
                "info": "Template for formatting BoardGameGeek search results. Available placeholders: {id}, {name}, {game_name}, {description}, {domains}, {mechanics}, {year_published}, {min_players}, {max_players}, {play_time}, {min_age}, {users_rated}, {rating_average}, {bgg_rank}, {complexity_average}, {owned_users}, {url}, {rank}, {score}. Leave empty for JSON output. Use 'DEBUG' to see available fields.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{rank}. {name} ({year_published}) - {rating_average}/10"
              },
              "search_method": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Method",
                "dynamic": false,
                "info": "Determine how your content is matched: Vector finds semantic similarity.",
                "name": "search_method",
                "options": [
                  "Vector Search"
                ],
                "options_metadata": [
                  {
                    "icon": "SearchVector"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Vector Search"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "search_score_threshold": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Search Score Threshold",
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "list": false,
                "list_add_label": "Add More",
                "name": "search_score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Type",
                "dynamic": false,
                "info": "Search type to use",
                "name": "search_type",
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Similarity"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "vector_dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Vector Dimensions",
                "dynamic": false,
                "info": "Dimensions of the embedding vectors.",
                "list": false,
                "list_add_label": "Add More",
                "name": "vector_dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              }
            },
            "tool_mode": false
          },
          "selected_output": "search_results",
          "showNode": true,
          "type": "NeonDatabase"
        },
        "dragging": false,
        "id": "CustomComponent-AoAOF",
        "measured": {
          "height": 513,
          "width": 320
        },
        "position": {
          "x": 2141.2349181094432,
          "y": 1484.603307995615
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "NeonDatabase-IlpF8",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "VectorStore"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Ingest and search documents in Neon Database with pgvector. Handles pre-chunked data.",
            "display_name": "Neon Database",
            "documentation": "https://neon.tech/docs",
            "edited": true,
            "field_order": [
              "connection_string",
              "collection_name",
              "embedding_model",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "search_method",
              "vector_dimensions",
              "distance_metric",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "advanced_search_filter",
              "autodetect_collection",
              "content_field",
              "metadata_field",
              "deletion_field",
              "ignore_invalid_documents",
              "batch_size",
              "output_template",
              "neon_vectorstore_kwargs"
            ],
            "frozen": false,
            "icon": "PostgreSQL",
            "last_updated": "2025-09-26T01:16:35.920Z",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "group_outputs": false,
                "hidden": null,
                "method": "search_documents",
                "name": "search_results",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "as_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Vector Store Connection",
                "group_outputs": false,
                "hidden": true,
                "method": "as_vector_store",
                "name": "vectorstoreconnection",
                "options": null,
                "required_inputs": null,
                "selected": "VectorStore",
                "tool_mode": true,
                "types": [
                  "VectorStore"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "advanced_search_filter": {
                "_input_type": "NestedDictInput",
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "list": false,
                "list_add_label": "Add More",
                "name": "advanced_search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "NestedDict",
                "value": {}
              },
              "autodetect_collection": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Autodetect Collection",
                "dynamic": false,
                "info": "Boolean flag to determine whether to autodetect the collection.",
                "list": false,
                "list_add_label": "Add More",
                "name": "autodetect_collection",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "batch_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Batch Size",
                "dynamic": false,
                "info": "Number of documents to process in each batch to avoid token limits.",
                "list": false,
                "list_add_label": "Add More",
                "name": "batch_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\r\nimport asyncio\r\nfrom collections import defaultdict\r\nfrom dataclasses import asdict, dataclass, field\r\nfrom typing import Optional, List, Dict, Any\r\n\r\nimport psycopg2\r\nfrom psycopg2.extras import RealDictCursor\r\nfrom sqlalchemy import create_engine, text\r\nfrom pgvector.sqlalchemy import Vector\r\nfrom langchain_postgres import PGVector\r\nfrom langchain_core.documents import Document\r\nfrom langchain_core.embeddings import Embeddings\r\n\r\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom langflow.base.vectorstores.vector_store_connection_decorator import vector_store_connection\r\nfrom langflow.helpers.data import docs_to_data\r\nfrom langflow.inputs.inputs import FloatInput, NestedDictInput\r\nfrom langflow.io import (\r\n    BoolInput,\r\n    DropdownInput,\r\n    HandleInput,\r\n    IntInput,\r\n    QueryInput,\r\n    SecretStrInput,\r\n    StrInput,\r\n)\r\nfrom langflow.schema.data import Data\r\nfrom langflow.serialization import serialize\r\nfrom langflow.utils.version import get_version_info\r\n\r\n\r\n@vector_store_connection\r\nclass NeonDatabaseVectorStoreComponent(LCVectorStoreComponent):\r\n    display_name: str = \"Neon Database\"\r\n    description: str = \"Ingest and search documents in Neon Database with pgvector. Handles pre-chunked data.\"\r\n    documentation: str = \"https://neon.tech/docs\"\r\n    name = \"NeonDatabase\"\r\n    icon: str = \"PostgreSQL\"\r\n\r\n    _cached_vector_store: PGVector | None = None\r\n\r\n    @dataclass\r\n    class NewCollectionInput:\r\n        functionality: str = \"create\"\r\n        fields: dict[str, dict] = field(\r\n            default_factory=lambda: {\r\n                \"data\": {\r\n                    \"node\": {\r\n                        \"name\": \"create_collection\",\r\n                        \"description\": \"Please allow several seconds for creation to complete.\",\r\n                        \"display_name\": \"Create new collection\",\r\n                        \"field_order\": [\r\n                            \"01_new_collection_name\",\r\n                            \"02_dimension\",\r\n                            \"03_distance_metric\",\r\n                        ],\r\n                        \"template\": {\r\n                            \"01_new_collection_name\": StrInput(\r\n                                name=\"new_collection_name\",\r\n                                display_name=\"Collection Name\",\r\n                                info=\"Name of the new collection to create in Neon Database.\",\r\n                                required=True,\r\n                            ),\r\n                            \"02_dimension\": IntInput(\r\n                                name=\"dimension\",\r\n                                display_name=\"Vector Dimensions\",\r\n                                info=\"Dimensions of the vectors to store.\",\r\n                                value=1536,\r\n                                required=True,\r\n                            ),\r\n                            \"03_distance_metric\": DropdownInput(\r\n                                name=\"distance_metric\",\r\n                                display_name=\"Distance Metric\",\r\n                                info=\"Distance metric for vector similarity search.\",\r\n                                options=[\"cosine\", \"euclidean\", \"inner_product\"],\r\n                                value=\"cosine\",\r\n                                required=True,\r\n                            ),\r\n                        },\r\n                    },\r\n                }\r\n            }\r\n        )\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"connection_string\",\r\n            display_name=\"Connection String\",\r\n            info=\"Direct connection string to your Neon Database. Get this from Neon Console → Connection Details. Format: postgresql://user:pass@host:port/db?sslmode=require\",\r\n            required=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"collection_name\",\r\n            display_name=\"Collection\",\r\n            info=\"The name of the collection (table) within Neon Database where the vectors will be stored.\",\r\n            required=True,\r\n            refresh_button=True,\r\n            real_time_refresh=True,\r\n            dialog_inputs=asdict(NewCollectionInput()),\r\n            combobox=True,\r\n        ),\r\n        HandleInput(\r\n            name=\"embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Specify the Embedding Model for vector generation.\",\r\n            required=True,\r\n        ),\r\n        *LCVectorStoreComponent.inputs,\r\n        DropdownInput(\r\n            name=\"search_method\",\r\n            display_name=\"Search Method\",\r\n            info=\"Determine how your content is matched: Vector finds semantic similarity.\",\r\n            options=[\"Vector Search\"],\r\n            options_metadata=[{\"icon\": \"SearchVector\"}],\r\n            value=\"Vector Search\",\r\n            advanced=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        IntInput(\r\n            name=\"vector_dimensions\",\r\n            display_name=\"Vector Dimensions\",\r\n            info=\"Dimensions of the embedding vectors.\",\r\n            advanced=True,\r\n            value=1536,\r\n        ),\r\n        DropdownInput(\r\n            name=\"distance_metric\",\r\n            display_name=\"Distance Metric\",\r\n            info=\"Distance metric for vector similarity search.\",\r\n            options=[\"cosine\", \"euclidean\", \"inner_product\"],\r\n            value=\"cosine\",\r\n            advanced=True,\r\n        ),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Search Results\",\r\n            info=\"Number of search results to return.\",\r\n            advanced=True,\r\n            value=4,\r\n        ),\r\n        DropdownInput(\r\n            name=\"search_type\",\r\n            display_name=\"Search Type\",\r\n            info=\"Search type to use\",\r\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\r\n            value=\"Similarity\",\r\n            advanced=True,\r\n        ),\r\n        FloatInput(\r\n            name=\"search_score_threshold\",\r\n            display_name=\"Search Score Threshold\",\r\n            info=\"Minimum similarity score threshold for search results. \"\r\n            \"(when using 'Similarity with score threshold')\",\r\n            value=0,\r\n            advanced=True,\r\n        ),\r\n        NestedDictInput(\r\n            name=\"advanced_search_filter\",\r\n            display_name=\"Search Metadata Filter\",\r\n            info=\"Optional dictionary of filters to apply to the search query.\",\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"autodetect_collection\",\r\n            display_name=\"Autodetect Collection\",\r\n            info=\"Boolean flag to determine whether to autodetect the collection.\",\r\n            advanced=True,\r\n            value=True,\r\n        ),\r\n        StrInput(\r\n            name=\"content_field\",\r\n            display_name=\"Content Field\",\r\n            info=\"Field to use as the text content field for the vector store.\",\r\n            advanced=True,\r\n            value=\"page_content\",\r\n        ),\r\n        StrInput(\r\n            name=\"metadata_field\",\r\n            display_name=\"Metadata Field\",\r\n            info=\"Field to use for storing document metadata.\",\r\n            advanced=True,\r\n            value=\"metadata\",\r\n        ),\r\n        StrInput(\r\n            name=\"deletion_field\",\r\n            display_name=\"Deletion Based On Field\",\r\n            info=\"When this parameter is provided, documents in the target collection with \"\r\n            \"metadata field values matching the input metadata field value will be deleted \"\r\n            \"before new data is loaded.\",\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"ignore_invalid_documents\",\r\n            display_name=\"Ignore Invalid Documents\",\r\n            info=\"Boolean flag to determine whether to ignore invalid documents at runtime.\",\r\n            advanced=True,\r\n        ),\r\n        IntInput(\r\n            name=\"batch_size\",\r\n            display_name=\"Batch Size\",\r\n            info=\"Number of documents to process in each batch to avoid token limits.\",\r\n            advanced=True,\r\n            value=10,\r\n        ),\r\n        StrInput(\r\n            name=\"output_template\",\r\n            display_name=\"Output Template\",\r\n            info=\"Template for formatting BoardGameGeek search results. Available placeholders: {id}, {name}, {game_name}, {description}, {domains}, {mechanics}, {year_published}, {min_players}, {max_players}, {play_time}, {min_age}, {users_rated}, {rating_average}, {bgg_rank}, {complexity_average}, {owned_users}, {url}, {rank}, {score}. Leave empty for JSON output. Use 'DEBUG' to see available fields.\",\r\n            advanced=True,\r\n            value=\"Game: {name}\\nYear: {year_published}\\nRating: {rating_average}/10 (BGG Rank #{bgg_rank})\\nPlayers: {min_players}-{max_players} | Time: {play_time}min | Age: {min_age}+\\nType: {domains}\\nMechanics: {mechanics}\\nComplexity: {complexity_average}/5\\nDescription: {description}\",\r\n        ),\r\n        NestedDictInput(\r\n            name=\"neon_vectorstore_kwargs\",\r\n            display_name=\"Neon VectorStore Parameters\",\r\n            info=\"Optional dictionary of additional parameters for the PGVector store.\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    @classmethod\r\n    def _get_content_field(cls) -> str:\r\n        return \"page_content\"\r\n    \r\n    @classmethod\r\n    def _get_metadata_field(cls) -> str:\r\n        return \"metadata\"\r\n\r\n    def get_database_object(self):\r\n        \"\"\"Get database connection object.\"\"\"\r\n        try:\r\n            if not self.connection_string:\r\n                raise ValueError(\"Connection string is required\")\r\n                \r\n            engine = create_engine(self.connection_string)\r\n            return engine\r\n        except Exception as e:\r\n            msg = f\"Error creating database connection: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n    def collection_data(self, collection_name: str):\r\n        \"\"\"Get collection metadata and document count.\"\"\"\r\n        try:\r\n            engine = self.get_database_object()\r\n            \r\n            with engine.connect() as conn:\r\n                # Check if table exists\r\n                result = conn.execute(text(\"\"\"\r\n                    SELECT EXISTS (\r\n                        SELECT FROM information_schema.tables \r\n                        WHERE table_name = :table_name\r\n                    );\r\n                \"\"\"), {\"table_name\": collection_name})\r\n                \r\n                if not result.scalar():\r\n                    return None\r\n                \r\n                # Get document count\r\n                count_result = conn.execute(text(f\"SELECT COUNT(*) FROM {collection_name}\"))\r\n                return count_result.scalar()\r\n                \r\n        except Exception as e:\r\n            self.log(f\"Error checking collection data: {e}\")\r\n            return None\r\n\r\n    def _initialize_collection_options(self):\r\n        \"\"\"Initialize collection options for dropdown.\"\"\"\r\n        try:\r\n            engine = self.get_database_object()\r\n            collections = []\r\n            \r\n            with engine.connect() as conn:\r\n                # Get all tables that have vector columns\r\n                result = conn.execute(text(\"\"\"\r\n                    SELECT table_name \r\n                    FROM information_schema.columns \r\n                    WHERE column_name = 'embedding' \r\n                    AND table_schema = 'public';\r\n                \"\"\"))\r\n                \r\n                for row in result:\r\n                    table_name = row[0]\r\n                    collections.append({\r\n                        \"name\": table_name,\r\n                        \"records\": self.collection_data(table_name),\r\n                        \"type\": \"vector_table\",\r\n                    })\r\n                    \r\n            return collections\r\n        except Exception as e:\r\n            self.log(f\"Error fetching collection options: {e}\")\r\n            return []\r\n\r\n    def reset_collection_list(self, build_config: dict) -> dict:\r\n        \"\"\"Reset collection list options based on provided configuration.\"\"\"\r\n        try:\r\n            if not self.connection_string:\r\n                collection_config = build_config[\"collection_name\"]\r\n                collection_config.update({\"options\": [], \"options_metadata\": [], \"value\": \"\", \"show\": False})\r\n                return build_config\r\n                \r\n            collection_options = self._initialize_collection_options()\r\n            \r\n            collection_config = build_config[\"collection_name\"]\r\n            collection_config.update(\r\n                {\r\n                    \"options\": [col[\"name\"] for col in collection_options],\r\n                    \"options_metadata\": [{k: v for k, v in col.items() if k != \"name\"} for col in collection_options],\r\n                }\r\n            )\r\n            \r\n            if collection_config[\"value\"] not in collection_config[\"options\"]:\r\n                collection_config[\"value\"] = \"\"\r\n                \r\n            collection_config[\"show\"] = bool(self.connection_string)\r\n            \r\n        except Exception as e:\r\n            self.log(f\"Error resetting collection list: {e}\")\r\n            \r\n        return build_config\r\n\r\n    def reset_build_config(self, build_config: dict) -> dict:\r\n        \"\"\"Reset all build configuration options to default empty state.\"\"\"\r\n        collection_config = build_config[\"collection_name\"]\r\n        collection_config.update({\"options\": [], \"options_metadata\": [], \"value\": \"\", \"show\": False})\r\n        \r\n        # For Neon Database, embedding model is always required\r\n        build_config[\"embedding_model\"][\"show\"] = True\r\n        build_config[\"embedding_model\"][\"required\"] = True\r\n        \r\n        return build_config\r\n\r\n    async def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\r\n        \"\"\"Update build configuration based on field name and value.\"\"\"\r\n        # Collection creation callback\r\n        if field_name == \"collection_name\" and isinstance(field_value, dict):\r\n            if \"01_new_collection_name\" in field_value:\r\n                await self._create_new_collection(build_config, field_value)\r\n                return build_config\r\n                \r\n        # Connection string change\r\n        if field_name == \"connection_string\":\r\n            return self.reset_collection_list(build_config)\r\n            \r\n        # Collection selection change\r\n        if field_name == \"collection_name\" and not isinstance(field_value, dict):\r\n            return self._handle_collection_selection(build_config, field_value)\r\n            \r\n        # Initial execution\r\n        first_run = field_name == \"collection_name\" and not field_value and not build_config[\"collection_name\"][\"options\"]\r\n        if first_run:\r\n            return self.reset_collection_list(build_config)\r\n            \r\n        return build_config\r\n\r\n    async def _create_new_collection(self, build_config: dict, field_value: dict) -> None:\r\n        \"\"\"Create a new collection and update build config options.\"\"\"\r\n        try:\r\n            await self.create_collection_api(\r\n                new_collection_name=field_value[\"01_new_collection_name\"],\r\n                connection_string=self.connection_string,\r\n                dimension=field_value.get(\"02_dimension\", 1536),\r\n                distance_metric=field_value.get(\"03_distance_metric\", \"cosine\"),\r\n            )\r\n        except Exception as e:\r\n            msg = f\"Error creating collection: {e}\"\r\n            raise ValueError(msg) from e\r\n            \r\n        build_config[\"collection_name\"].update(\r\n            {\r\n                \"value\": field_value[\"01_new_collection_name\"],\r\n                \"options\": build_config[\"collection_name\"][\"options\"] + [field_value[\"01_new_collection_name\"]],\r\n            }\r\n        )\r\n        \r\n        build_config[\"collection_name\"][\"options_metadata\"].append(\r\n            {\r\n                \"records\": 0,\r\n                \"type\": \"vector_table\",\r\n            }\r\n        )\r\n        \r\n        # Show embedding model input since we're using \"Bring your own\" approach\r\n        build_config[\"embedding_model\"][\"show\"] = True\r\n        build_config[\"embedding_model\"][\"required\"] = True\r\n\r\n    @classmethod\r\n    async def create_collection_api(\r\n        cls,\r\n        new_collection_name: str,\r\n        connection_string: str,\r\n        dimension: int,\r\n        distance_metric: str = \"cosine\",\r\n    ):\r\n        \"\"\"Create a new collection (table) in Neon Database.\"\"\"\r\n        try:\r\n            # Create engine\r\n            engine = create_engine(connection_string)\r\n            \r\n            # Create the vector table\r\n            with engine.connect() as conn:\r\n                # Enable pgvector extension\r\n                conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector\"))\r\n                \r\n                # Create the collection table\r\n                create_table_sql = f\"\"\"\r\n                CREATE TABLE IF NOT EXISTS {new_collection_name} (\r\n                    id SERIAL PRIMARY KEY,\r\n                    {cls._get_content_field()} TEXT NOT NULL,\r\n                    {cls._get_metadata_field()} JSONB,\r\n                    embedding vector({dimension})\r\n                );\r\n                \"\"\"\r\n                conn.execute(text(create_table_sql))\r\n                \r\n                # Create index based on distance metric\r\n                index_sql = f\"\"\"\r\n                CREATE INDEX IF NOT EXISTS {new_collection_name}_embedding_idx \r\n                ON {new_collection_name} \r\n                USING ivfflat (embedding vector_{distance_metric}_ops) \r\n                WITH (lists = 100);\r\n                \"\"\"\r\n                conn.execute(text(index_sql))\r\n                \r\n                conn.commit()\r\n                \r\n        except Exception as e:\r\n            msg = f\"Error creating collection: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n    def _handle_collection_selection(self, build_config: dict, field_value: str) -> dict:\r\n        \"\"\"Handle collection selection and update embedding options.\"\"\"\r\n        build_config[\"autodetect_collection\"][\"value\"] = True\r\n        build_config = self.reset_collection_list(build_config)\r\n        \r\n        if not field_value:\r\n            return build_config\r\n            \r\n        if field_value and field_value not in build_config[\"collection_name\"][\"options\"]:\r\n            build_config[\"collection_name\"][\"options\"].append(field_value)\r\n            build_config[\"collection_name\"][\"options_metadata\"].append(\r\n                {\r\n                    \"records\": 0,\r\n                    \"type\": \"vector_table\",\r\n                }\r\n            )\r\n            build_config[\"autodetect_collection\"][\"value\"] = False\r\n        \r\n        # For Neon Database, we always need an embedding model since we don't have built-in vectorize\r\n        build_config[\"embedding_model\"][\"show\"] = True\r\n        build_config[\"embedding_model\"][\"required\"] = True\r\n            \r\n        return build_config\r\n\r\n    @check_cached_vector_store\r\n    def build_vector_store(self):\r\n        \"\"\"Build the PGVector store.\"\"\"\r\n        try:\r\n            from langchain_postgres import PGVector\r\n        except ImportError as e:\r\n            msg = (\r\n                \"Could not import langchain_postgres package. \"\r\n                \"Please install it with `pip install langchain-postgres`.\"\r\n            )\r\n            raise ImportError(msg) from e\r\n\r\n        # Get the embedding model and additional params\r\n        embedding_params = {\"embedding\": self.embedding_model} if self.embedding_model else {}\r\n        \r\n        if not embedding_params:\r\n            raise ValueError(\"Embedding model is required for Neon Database vector store\")\r\n\r\n        # Get the additional parameters\r\n        additional_params = self.neon_vectorstore_kwargs or {}\r\n\r\n        # Get Langflow version information\r\n        __version__ = get_version_info()[\"version\"]\r\n\r\n        # Get connection details\r\n        if not self.connection_string:\r\n            raise ValueError(\"Connection string is required for Neon Database\")\r\n\r\n        # Bundle up the auto-detect parameters\r\n        autodetect_params = {\r\n            \"pre_delete_collection\": False,\r\n            \"distance_strategy\": self._get_distance_strategy(),\r\n            \"create_extension\": True,\r\n        }\r\n\r\n        # Attempt to build the Vector Store object\r\n        try:\r\n            vector_store = PGVector(\r\n                connection=self.connection_string,\r\n                embeddings=self.embedding_model,\r\n                collection_name=self.collection_name,\r\n                collection_metadata={\"langflow_version\": __version__},\r\n                **autodetect_params,\r\n                **additional_params,\r\n            )\r\n        except Exception as e:\r\n            msg = f\"Error initializing PGVector: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n        # Add documents to the vector store in batches\r\n        self._add_documents_to_vector_store_batched(vector_store)\r\n\r\n        return vector_store\r\n\r\n    def _get_distance_strategy(self) -> str:\r\n        \"\"\"Map distance metric to PGVector distance strategy.\"\"\"\r\n        distance_mapping = {\r\n            \"cosine\": \"cosine\",\r\n            \"euclidean\": \"euclidean\", \r\n            \"inner_product\": \"inner_product\",\r\n        }\r\n        return distance_mapping.get(self.distance_metric, \"cosine\")\r\n\r\n    def _add_documents_to_vector_store_batched(self, vector_store) -> None:\r\n        \"\"\"Add documents to the vector store in batches to avoid token limits.\"\"\"\r\n        self.ingest_data = self._prepare_ingest_data()\r\n\r\n        if not self.ingest_data:\r\n            self.log(\"No documents to add to the Vector Store.\")\r\n            return\r\n\r\n        documents = []\r\n        for _input in self.ingest_data:\r\n            if isinstance(_input, Data):\r\n                documents.append(_input.to_lc_document())\r\n            else:\r\n                msg = \"Vector Store Inputs must be Data objects.\"\r\n                raise TypeError(msg)\r\n\r\n        # Convert to Document objects with serialized metadata\r\n        documents = [\r\n            Document(page_content=doc.page_content, metadata=serialize(doc.metadata, to_str=True)) \r\n            for doc in documents\r\n        ]\r\n\r\n        if documents and self.deletion_field:\r\n            self.log(f\"Deleting documents where {self.deletion_field}\")\r\n            try:\r\n                # Implement deletion logic if needed\r\n                self.log(f\"Deletion field '{self.deletion_field}' specified but deletion not implemented yet.\")\r\n            except Exception as e:\r\n                msg = f\"Error deleting documents from PGVector based on '{self.deletion_field}': {e}\"\r\n                raise ValueError(msg) from e\r\n\r\n        if documents:\r\n            self.log(f\"Adding {len(documents)} documents to the Vector Store in batches of {self.batch_size}.\")\r\n            \r\n            # Process documents in batches\r\n            total_batches = (len(documents) + self.batch_size - 1) // self.batch_size\r\n            \r\n            for i in range(0, len(documents), self.batch_size):\r\n                batch = documents[i:i + self.batch_size]\r\n                batch_num = (i // self.batch_size) + 1\r\n                \r\n                try:\r\n                    self.log(f\"Processing batch {batch_num}/{total_batches} ({len(batch)} documents)\")\r\n                    vector_store.add_documents(batch)\r\n                    self.log(f\"Successfully added batch {batch_num}\")\r\n                except Exception as e:\r\n                    self.log(f\"Error adding batch {batch_num}: {e}\")\r\n                    # Continue with next batch instead of failing completely\r\n                    continue\r\n                    \r\n            self.log(f\"Completed processing all {len(documents)} documents.\")\r\n        else:\r\n            self.log(\"No documents to add to the Vector Store.\")\r\n\r\n    def _map_search_type(self) -> str:\r\n        \"\"\"Map search type to PGVector search method.\"\"\"\r\n        search_type_mapping = {\r\n            \"Similarity with score threshold\": \"similarity_score_threshold\",\r\n            \"MMR (Max Marginal Relevance)\": \"mmr\",\r\n        }\r\n        return search_type_mapping.get(self.search_type, \"similarity\")\r\n\r\n    def _build_search_args(self):\r\n        \"\"\"Build search arguments for vector store search.\"\"\"\r\n        query = self.search_query if isinstance(self.search_query, str) and self.search_query.strip() else None\r\n\r\n        if not query:\r\n            return {}\r\n\r\n        args = {\r\n            \"query\": query,\r\n            \"search_type\": self._map_search_type(),\r\n            \"k\": self.number_of_results,\r\n        }\r\n\r\n        if self.search_type == \"Similarity with score threshold\":\r\n            args[\"score_threshold\"] = self.search_score_threshold\r\n\r\n        filter_arg = self.advanced_search_filter or {}\r\n        if filter_arg:\r\n            args[\"filter\"] = filter_arg\r\n\r\n        return args\r\n\r\n    def search_documents(self, vector_store=None) -> Data:\r\n        \"\"\"Search documents in the vector store and return formatted results as a single Data object.\"\"\"\r\n        vector_store = vector_store or self.build_vector_store()\r\n\r\n        self.log(f\"Search input: {self.search_query}\")\r\n        self.log(f\"Search type: {self.search_type}\")\r\n        self.log(f\"Number of results: {self.number_of_results}\")\r\n\r\n        try:\r\n            search_args = self._build_search_args()\r\n        except Exception as e:\r\n            msg = f\"Error in PGVector._build_search_args: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n        if not search_args:\r\n            self.log(\"No search input provided. Skipping search.\")\r\n            return Data(text=\"\", display_name=\"No Search Results\")\r\n\r\n        docs = []\r\n        search_method = \"similarity_search\"\r\n\r\n        try:\r\n            self.log(f\"Calling vector_store.{search_method} with args: {search_args}\")\r\n            docs = getattr(vector_store, search_method)(**search_args)\r\n        except Exception as e:\r\n            msg = f\"Error performing {search_method} in PGVector: {e}\"\r\n            raise ValueError(msg) from e\r\n\r\n        self.log(f\"Retrieved documents: {len(docs)}\")\r\n\r\n        # Convert documents to a single formatted Data object for parsers\r\n        formatted_data = self._format_search_results_for_parser(docs)\r\n        self.log(f\"Formatted documents for parser: {formatted_data.display_name}\")\r\n        self.status = formatted_data\r\n\r\n        return formatted_data\r\n\r\n    def _format_search_results_for_parser(self, docs) -> Data:\r\n        \"\"\"Format search results for use with Langflow parsers and templates.\"\"\"\r\n        if not docs:\r\n            return Data(text=\"\", display_name=\"No Search Results\")\r\n        \r\n        # Check if we're in debug mode\r\n        if self.output_template and self.output_template.strip().upper() == \"DEBUG\":\r\n            return self._debug_mode_output(docs)\r\n        \r\n        # Parse all documents and format them\r\n        parsed_games = []\r\n        \r\n        for i, doc in enumerate(docs):\r\n            # Extract game data from metadata and content\r\n            metadata = doc.metadata or {}\r\n            content = doc.page_content\r\n            \r\n            # Parse the CSV content to extract game data\r\n            game_data = self._parse_csv_content(content, metadata, i + 1)\r\n            parsed_games.append(game_data)\r\n        \r\n        # If using a template, format the results\r\n        self.log(f\"Output template value: '{self.output_template}'\")\r\n        self.log(f\"Template condition check: template='{self.output_template}', strip='{self.output_template.strip() if self.output_template else None}', condition={bool(self.output_template and self.output_template.strip())}\")\r\n        \r\n        if self.output_template and self.output_template.strip():\r\n            formatted_results = []\r\n            \r\n            for game_data in parsed_games:\r\n                # Convert lists to strings for template formatting\r\n                mechanics_str = \", \".join(game_data[\"mechanics\"]) if isinstance(game_data[\"mechanics\"], list) else str(game_data[\"mechanics\"])\r\n                domains_str = \", \".join(game_data[\"domains\"]) if isinstance(game_data[\"domains\"], list) else str(game_data[\"domains\"])\r\n                \r\n                try:\r\n                    # Use safe formatting with default values\r\n                    formatted_result = self.output_template.format(\r\n                        id=game_data.get(\"id\", \"Unknown\"),\r\n                        game_name=game_data.get(\"game_name\", \"Unknown\"),\r\n                        name=game_data.get(\"name\", \"Unknown\"),\r\n                        description=game_data.get(\"description\", \"No description available\"),\r\n                        domains=domains_str,\r\n                        mechanics=mechanics_str,\r\n                        year_published=game_data.get(\"year_published\", \"Unknown\"),\r\n                        min_players=game_data.get(\"min_players\", \"Unknown\"),\r\n                        max_players=game_data.get(\"max_players\", \"Unknown\"),\r\n                        play_time=game_data.get(\"play_time\", \"Unknown\"),\r\n                        min_age=game_data.get(\"min_age\", \"Unknown\"),\r\n                        users_rated=game_data.get(\"users_rated\", \"Unknown\"),\r\n                        rating_average=game_data.get(\"rating_average\", \"Unknown\"),\r\n                        bgg_rank=game_data.get(\"bgg_rank\", \"Unknown\"),\r\n                        complexity_average=game_data.get(\"complexity_average\", \"Unknown\"),\r\n                        owned_users=game_data.get(\"owned_users\", \"Unknown\"),\r\n                        url=game_data.get(\"url\", \"Unknown\"),\r\n                        rank=game_data.get(\"rank\", \"Unknown\"),\r\n                        score=game_data.get(\"score\", \"N/A\")\r\n                    )\r\n                    formatted_results.append(formatted_result)\r\n                except KeyError as e:\r\n                    self.log(f\"Template error for game {game_data.get('game_name', 'Unknown')} - missing key {e}\")\r\n                    # Fall back to a simple format\r\n                    simple_result = f\"{game_data.get('rank', '?')}. {game_data.get('name', 'Unknown Game')}\"\r\n                    formatted_results.append(simple_result)\r\n            \r\n            # Combine all formatted results into a single text\r\n            combined_text = \"\\n\\n\".join(formatted_results)\r\n            \r\n            return Data(\r\n                text=combined_text,\r\n                display_name=f\"Search Results: {len(formatted_results)} games found\",\r\n                metadata={\"source\": \"neon_search\", \"total_results\": len(formatted_results), \"template_used\": True}\r\n            )\r\n        \r\n        else:\r\n            # Return structured data with individual fields for each game\r\n            self.log(\"Taking non-template path - returning structured data with individual fields\")\r\n            \r\n            # Create a single Data object with all game data as separate fields\r\n            # This allows the parser to access individual fields like rank, name, etc.\r\n            \r\n            # For now, let's return the first game's data as individual fields\r\n            # and put all games' data in the text field\r\n            if parsed_games:\r\n                first_game = parsed_games[0]\r\n                \r\n                # Create a single Data object with individual fields from the first game\r\n                # and all games' data in the text field\r\n                all_games_text = \"\\n\\n\".join([\r\n                    f\"Game {i+1}: {game['name']} ({game['year_published']}) - {game['rating_average']}/10\"\r\n                    for i, game in enumerate(parsed_games)\r\n                ])\r\n                \r\n                return Data(\r\n                    text=all_games_text,\r\n                    rank=first_game.get(\"rank\", 1),\r\n                    id=first_game.get(\"id\", \"Unknown\"),\r\n                    name=first_game.get(\"name\", \"Unknown\"),\r\n                    game_name=first_game.get(\"game_name\", \"Unknown\"),\r\n                    year_published=first_game.get(\"year_published\", \"Unknown\"),\r\n                    min_players=first_game.get(\"min_players\", \"Unknown\"),\r\n                    max_players=first_game.get(\"max_players\", \"Unknown\"),\r\n                    play_time=first_game.get(\"play_time\", \"Unknown\"),\r\n                    min_age=first_game.get(\"min_age\", \"Unknown\"),\r\n                    users_rated=first_game.get(\"users_rated\", \"Unknown\"),\r\n                    rating_average=first_game.get(\"rating_average\", \"Unknown\"),\r\n                    bgg_rank=first_game.get(\"bgg_rank\", \"Unknown\"),\r\n                    complexity_average=first_game.get(\"complexity_average\", \"Unknown\"),\r\n                    owned_users=first_game.get(\"owned_users\", \"Unknown\"),\r\n                    mechanics=\", \".join(first_game.get(\"mechanics\", [])),\r\n                    domains=\", \".join(first_game.get(\"domains\", [])),\r\n                    url=first_game.get(\"url\", \"Unknown\"),\r\n                    description=first_game.get(\"description\", \"No description available\"),\r\n                    display_name=f\"Search Results: {len(parsed_games)} games found\",\r\n                    metadata={\"source\": \"neon_search\", \"total_results\": len(parsed_games), \"format\": \"structured\"}\r\n                )\r\n            else:\r\n                # No games found\r\n                return Data(\r\n                    text=\"No games found\",\r\n                    rank=0,\r\n                    id=\"Unknown\",\r\n                    name=\"Unknown\",\r\n                    game_name=\"Unknown\",\r\n                    year_published=\"Unknown\",\r\n                    min_players=\"Unknown\",\r\n                    max_players=\"Unknown\",\r\n                    play_time=\"Unknown\",\r\n                    min_age=\"Unknown\",\r\n                    users_rated=\"Unknown\",\r\n                    rating_average=\"Unknown\",\r\n                    bgg_rank=\"Unknown\",\r\n                    complexity_average=\"Unknown\",\r\n                    owned_users=\"Unknown\",\r\n                    mechanics=\"Unknown\",\r\n                    domains=\"Unknown\",\r\n                    url=\"Unknown\",\r\n                    description=\"No games found\",\r\n                    display_name=\"Search Results: 0 games found\",\r\n                    metadata={\"source\": \"neon_search\", \"total_results\": 0, \"format\": \"structured\"}\r\n                )\r\n\r\n    def _debug_mode_output(self, docs) -> Data:\r\n        \"\"\"Debug mode to show what data is actually available.\"\"\"\r\n        debug_info = []\r\n        debug_info.append(\"=== DEBUG MODE: Available Data Fields ===\")\r\n        debug_info.append(f\"Found {len(docs)} documents\")\r\n        debug_info.append(\"\")\r\n        \r\n        for i, doc in enumerate(docs[:3]):  # Show first 3 documents\r\n            debug_info.append(f\"--- Document {i+1} ---\")\r\n            debug_info.append(f\"Page Content (first 200 chars): {doc.page_content[:200]}...\")\r\n            debug_info.append(f\"Metadata keys: {list(doc.metadata.keys()) if doc.metadata else 'No metadata'}\")\r\n            \r\n            if doc.metadata:\r\n                for key, value in doc.metadata.items():\r\n                    if isinstance(value, (list, dict)):\r\n                        debug_info.append(f\"  {key}: {type(value).__name__} with {len(value)} items\")\r\n                    else:\r\n                        debug_info.append(f\"  {key}: {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}\")\r\n            debug_info.append(\"\")\r\n        \r\n        debug_text = \"\\n\".join(debug_info)\r\n        \r\n        return Data(\r\n            text=debug_text,\r\n            display_name=\"Debug: Data Structure Analysis\",\r\n            metadata={\"source\": \"neon_search\", \"debug_mode\": True, \"total_docs\": len(docs)}\r\n        )\r\n\r\n    def _parse_csv_content(self, content, metadata, rank):\r\n        \"\"\"Parse CSV content to extract game data.\"\"\"\r\n        import csv\r\n        import io\r\n        \r\n        try:\r\n            # Split the content by commas, but handle quoted fields properly\r\n            reader = csv.reader(io.StringIO(content))\r\n            row = next(reader)\r\n            \r\n            # Expected CSV format: ID,Name,Year,MinPlayers,MaxPlayers,PlayTime,MinAge,UsersRated,Rating,BGGRank,Complexity,OwnedUsers,Mechanics,Domains,URL,Description\r\n            if len(row) >= 16:\r\n                game_data = {\r\n                    \"rank\": rank,\r\n                    \"content\": content,\r\n                    \"metadata\": metadata,\r\n                    \"score\": None,\r\n                    \"id\": row[0] if row[0] else \"Unknown\",\r\n                    \"name\": row[1] if row[1] else \"Unknown\",\r\n                    \"game_name\": row[1] if row[1] else \"Unknown\",\r\n                    \"year_published\": row[2] if row[2] else \"Unknown\",\r\n                    \"min_players\": row[3] if row[3] else \"Unknown\",\r\n                    \"max_players\": row[4] if row[4] else \"Unknown\",\r\n                    \"play_time\": row[5] if row[5] else \"Unknown\",\r\n                    \"min_age\": row[6] if row[6] else \"Unknown\",\r\n                    \"users_rated\": row[7] if row[7] else \"Unknown\",\r\n                    \"rating_average\": row[8] if row[8] else \"Unknown\",\r\n                    \"bgg_rank\": row[9] if row[9] else \"Unknown\",\r\n                    \"complexity_average\": row[10] if row[10] else \"Unknown\",\r\n                    \"owned_users\": row[11] if row[11] else \"Unknown\",\r\n                    \"mechanics\": row[12].split(\", \") if row[12] else [],\r\n                    \"domains\": row[13].split(\", \") if row[13] else [],\r\n                    \"url\": row[14] if row[14] else \"Unknown\",\r\n                    \"description\": row[15] if row[15] else \"No description available\",\r\n                }\r\n            else:\r\n                # Fallback if CSV format is different\r\n                game_data = {\r\n                    \"rank\": rank,\r\n                    \"content\": content,\r\n                    \"metadata\": metadata,\r\n                    \"score\": None,\r\n                    \"id\": \"Unknown\",\r\n                    \"name\": \"Unknown\",\r\n                    \"game_name\": \"Unknown\",\r\n                    \"year_published\": \"Unknown\",\r\n                    \"min_players\": \"Unknown\",\r\n                    \"max_players\": \"Unknown\",\r\n                    \"play_time\": \"Unknown\",\r\n                    \"min_age\": \"Unknown\",\r\n                    \"users_rated\": \"Unknown\",\r\n                    \"rating_average\": \"Unknown\",\r\n                    \"bgg_rank\": \"Unknown\",\r\n                    \"complexity_average\": \"Unknown\",\r\n                    \"owned_users\": \"Unknown\",\r\n                    \"mechanics\": [],\r\n                    \"domains\": [],\r\n                    \"url\": \"Unknown\",\r\n                    \"description\": content,\r\n                }\r\n                \r\n        except Exception as e:\r\n            self.log(f\"Error parsing CSV content: {e}\")\r\n            # Fallback to basic parsing\r\n            game_data = {\r\n                \"rank\": rank,\r\n                \"content\": content,\r\n                \"metadata\": metadata,\r\n                \"score\": None,\r\n                \"id\": \"Unknown\",\r\n                \"name\": \"Unknown\",\r\n                \"game_name\": \"Unknown\",\r\n                \"year_published\": \"Unknown\",\r\n                \"min_players\": \"Unknown\",\r\n                \"max_players\": \"Unknown\",\r\n                \"play_time\": \"Unknown\",\r\n                \"min_age\": \"Unknown\",\r\n                \"users_rated\": \"Unknown\",\r\n                \"rating_average\": \"Unknown\",\r\n                \"bgg_rank\": \"Unknown\",\r\n                \"complexity_average\": \"Unknown\",\r\n                \"owned_users\": \"Unknown\",\r\n                \"mechanics\": [],\r\n                \"domains\": [],\r\n                \"url\": \"Unknown\",\r\n                \"description\": content,\r\n            }\r\n        \r\n        return game_data\r\n\r\n    def get_retriever_kwargs(self):\r\n        \"\"\"Get retriever kwargs for the vector store.\"\"\"\r\n        search_args = self._build_search_args()\r\n\r\n        return {\r\n            \"search_type\": self._map_search_type(),\r\n            \"search_kwargs\": search_args,\r\n        }\r\n"
              },
              "collection_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {
                  "fields": {
                    "data": {
                      "node": {
                        "description": "Please allow several seconds for creation to complete.",
                        "display_name": "Create new collection",
                        "field_order": [
                          "01_new_collection_name",
                          "02_dimension",
                          "03_distance_metric"
                        ],
                        "name": "create_collection",
                        "template": {
                          "01_new_collection_name": {
                            "_input_type": "StrInput",
                            "advanced": false,
                            "display_name": "Collection Name",
                            "dynamic": false,
                            "info": "Name of the new collection to create in Neon Database.",
                            "list": false,
                            "list_add_label": "Add More",
                            "load_from_db": false,
                            "name": "new_collection_name",
                            "placeholder": "",
                            "required": true,
                            "show": true,
                            "title_case": false,
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "type": "str",
                            "value": ""
                          },
                          "02_dimension": {
                            "_input_type": "IntInput",
                            "advanced": false,
                            "display_name": "Vector Dimensions",
                            "dynamic": false,
                            "info": "Dimensions of the vectors to store.",
                            "list": false,
                            "list_add_label": "Add More",
                            "name": "dimension",
                            "placeholder": "",
                            "required": true,
                            "show": true,
                            "title_case": false,
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "type": "int",
                            "value": 1536
                          },
                          "03_distance_metric": {
                            "_input_type": "DropdownInput",
                            "advanced": false,
                            "combobox": false,
                            "dialog_inputs": {},
                            "display_name": "Distance Metric",
                            "dynamic": false,
                            "info": "Distance metric for vector similarity search.",
                            "name": "distance_metric",
                            "options": [
                              "cosine",
                              "euclidean",
                              "inner_product"
                            ],
                            "options_metadata": [],
                            "placeholder": "",
                            "required": true,
                            "show": true,
                            "title_case": false,
                            "toggle": false,
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "type": "str",
                            "value": "cosine"
                          }
                        }
                      }
                    }
                  },
                  "functionality": "create"
                },
                "display_name": "Collection",
                "dynamic": false,
                "info": "The name of the collection (table) within Neon Database where the vectors will be stored.",
                "load_from_db": false,
                "name": "collection_name",
                "options": [
                  "documents",
                  "langchain_pg_embedding"
                ],
                "options_metadata": [
                  {
                    "records": 0,
                    "type": "vector_table"
                  },
                  {
                    "records": 31945,
                    "type": "vector_table"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "langchain_pg_embedding"
              },
              "connection_string": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Connection String",
                "dynamic": false,
                "info": "Direct connection string to your Neon Database. Get this from Neon Console → Connection Details. Format: postgresql://user:pass@host:port/db?sslmode=require",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "connection_string",
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "postgresql://neondb_owner:npg_fzoFW1Bn9GIr@ep-still-brook-af8h1onp-pooler.c-2.us-west-2.aws.neon.tech/neondb?sslmode=require&channel_binding=require"
              },
              "content_field": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Content Field",
                "dynamic": false,
                "info": "Field to use as the text content field for the vector store.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "content_field",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "page_content"
              },
              "deletion_field": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Deletion Based On Field",
                "dynamic": false,
                "info": "When this parameter is provided, documents in the target collection with metadata field values matching the input metadata field value will be deleted before new data is loaded.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "deletion_field",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "distance_metric": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Distance Metric",
                "dynamic": false,
                "info": "Distance metric for vector similarity search.",
                "name": "distance_metric",
                "options": [
                  "cosine",
                  "euclidean",
                  "inner_product"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              },
              "embedding_model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding Model",
                "dynamic": false,
                "info": "Specify the Embedding Model for vector generation.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding_model",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ignore_invalid_documents": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Invalid Documents",
                "dynamic": false,
                "info": "Boolean flag to determine whether to ignore invalid documents at runtime.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ignore_invalid_documents",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "metadata_field": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Field",
                "dynamic": false,
                "info": "Field to use for storing document metadata.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_field",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "metadata"
              },
              "neon_vectorstore_kwargs": {
                "_input_type": "NestedDictInput",
                "advanced": true,
                "display_name": "Neon VectorStore Parameters",
                "dynamic": false,
                "info": "Optional dictionary of additional parameters for the PGVector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "neon_vectorstore_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "NestedDict",
                "value": {}
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Search Results",
                "dynamic": false,
                "info": "Number of search results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "output_template": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Output Template",
                "dynamic": false,
                "info": "Template for formatting BoardGameGeek search results. Available placeholders: {id}, {name}, {game_name}, {description}, {domains}, {mechanics}, {year_published}, {min_players}, {max_players}, {play_time}, {min_age}, {users_rated}, {rating_average}, {bgg_rank}, {complexity_average}, {owned_users}, {url}, {rank}, {score}. Leave empty for JSON output. Use 'DEBUG' to see available fields.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_method": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Method",
                "dynamic": false,
                "info": "Determine how your content is matched: Vector finds semantic similarity.",
                "name": "search_method",
                "options": [
                  "Vector Search"
                ],
                "options_metadata": [
                  {
                    "icon": "SearchVector"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Vector Search"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "search_score_threshold": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Search Score Threshold",
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "list": false,
                "list_add_label": "Add More",
                "name": "search_score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Type",
                "dynamic": false,
                "info": "Search type to use",
                "name": "search_type",
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Similarity"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "vector_dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Vector Dimensions",
                "dynamic": false,
                "info": "Dimensions of the embedding vectors.",
                "list": false,
                "list_add_label": "Add More",
                "name": "vector_dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              }
            },
            "tool_mode": false
          },
          "selected_output": "search_results",
          "showNode": true,
          "type": "NeonDatabase"
        },
        "dragging": false,
        "id": "NeonDatabase-IlpF8",
        "measured": {
          "height": 513,
          "width": 320
        },
        "position": {
          "x": 1208.6495233808396,
          "y": 472.2540740767168
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-eJzz1",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Sends text output via API.",
            "display_name": "Text Output",
            "documentation": "https://docs.langflow.org/components-io#text-output",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.5.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-eJzz1",
        "measured": {
          "height": 202,
          "width": 320
        },
        "position": {
          "x": 2102.056091631759,
          "y": 266.83501710237675
        },
        "selected": true,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -695.0071696388613,
      "y": -92.79326912506303,
      "zoom": 0.885384468273271
    }
  },
  "description": "Load your data for chat context with Retrieval Augmented Generation.",
  "endpoint_name": null,
  "id": "50904071-2e67-4fa3-9e34-b3ef50368a94",
  "is_component": false,
  "last_tested_version": "1.5.1",
  "name": "Better Board Game Search",
  "tags": [
    "openai",
    "astradb",
    "rag",
    "q-a"
  ]
}